{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71437fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.patheffects as patheffects\n",
    "\n",
    "def get_results_mean(ontology_name, reasoner, metrics_index):\n",
    "    tasks = [\"Membership\", \"Link Prediction\"]\n",
    "    file_pattern = f\"models/results/{reasoner}/{ontology_name}*.txt\"  \n",
    "\n",
    "    data = []\n",
    "\n",
    "    for filepath in glob.glob(file_pattern, recursive=True):\n",
    "        filename = filepath.split(\"\\\\\")[-1] \n",
    "        parts = filename.replace(\".txt\", \"\").split(\"_\")\n",
    "        reasoner = f\"{reasoner}\"\n",
    "\n",
    "        if len(parts) == 1 or len(parts) == 2:  \n",
    "            ontology = f\"{ontology_name}\"\n",
    "            noise_type = \"None\"\n",
    "            noise_level = 0\n",
    "        elif len(parts) == 3: \n",
    "            ontology, noise_type, noise_level = parts\n",
    "        elif len(parts) == 4: \n",
    "            ontology_1, ontology_2, noise_type, noise_level = parts\n",
    "            ontology = ontology_1 + \"_\" + ontology_2\n",
    "        else:\n",
    "            print(f\"⚠️ Skipping file (unexpected filename): {filename}\")\n",
    "            continue\n",
    "\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        current_task = None\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.rstrip(\":\") in tasks:\n",
    "                current_task = line.rstrip(\":\")\n",
    "            elif line.startswith(\"Mean:\") and current_task:\n",
    "                mean_values = line.replace(\"Mean:\", \"\").split(\"&\")\n",
    "                mean_values = [float(x.strip()) for x in mean_values if x.strip()]\n",
    "                if len(mean_values) > metrics_index:\n",
    "                    mrr = mean_values[metrics_index]\n",
    "                    data.append({\n",
    "                        \"Ontology\": ontology,\n",
    "                        \"Reasoner\": reasoner,\n",
    "                        \"NoiseType\": noise_type,\n",
    "                        \"NoiseLevel\": noise_level,\n",
    "                        \"Task\": current_task,\n",
    "                        \"MRR\": mrr\n",
    "                    })\n",
    "                current_task = None\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def visualize(df, noise_type, title, output_file_name):\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\", font_scale=1.3)\n",
    "\n",
    "    # Filter data\n",
    "    df_noise_type = df[df['NoiseType'] == noise_type].copy()\n",
    "    df_noise_type['NoiseLevel'] = pd.to_numeric(df_noise_type['NoiseLevel'], errors='coerce')\n",
    "    df_noise_type['MRR'] = pd.to_numeric(df_noise_type['MRR'], errors='coerce')\n",
    "    df_noise_type = df_noise_type.dropna(subset=['NoiseLevel', 'MRR'])\n",
    "    df_owl2vec = df_noise_type[df_noise_type['Reasoner'] == 'owl2vec']\n",
    "    df_box2el = df_noise_type[df_noise_type['Reasoner'] == 'box2el']\n",
    "    df_gnn = df_noise_type[df_noise_type['Reasoner'] == 'rgcn_reasoner']\n",
    "\n",
    "    # Create side-by-side subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "    # Helper function for line plots with value annotations\n",
    "    def plot_line_with_values(ax, data, title):\n",
    "        palette = sns.color_palette(\"Set2\", n_colors=data['Task'].nunique())\n",
    "        task_order = data['Task'].drop_duplicates().tolist()  # ensure consistent order\n",
    "        task_color_map = {task: palette[i] for i, task in enumerate(task_order)}\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=data,\n",
    "            x=\"NoiseLevel\", y=\"MRR\", hue=\"Task\",\n",
    "            marker=\"o\", palette=\"Set2\", err_style=\"bars\", errorbar=\"sd\", ax=ax\n",
    "        )\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylim(0, 1.1)  # more room for labels\n",
    "        ax.set_xlabel(\"Noise Level\")\n",
    "        ax.set_ylabel(\"MRR\" if ax == axes[0] else \"\")\n",
    "        ax.grid(True)\n",
    "\n",
    "        # Set x-ticks with 0.25 spacing from min to max NoiseLevel\n",
    "        min_x, max_x = data['NoiseLevel'].min(), data['NoiseLevel'].max()\n",
    "        ticks = list(np.arange(min_x, max_x + 0.25, 0.25))\n",
    "        ax.set_xticks(ticks)\n",
    "\n",
    "        texts = []\n",
    "        for task in data['Task'].unique():\n",
    "            task_data = data[data['Task'] == task]\n",
    "            label_color = task_color_map.get(task, \"black\")\n",
    "            for _, row in task_data.iterrows():\n",
    "                texts.append(\n",
    "                    ax.text(\n",
    "                        row['NoiseLevel'], row['MRR'] + 0.04,\n",
    "                        f\"{row['MRR']:.3f}\",\n",
    "                        color=label_color,\n",
    "                        ha='center', va='bottom',\n",
    "                        fontsize=12,\n",
    "                        fontweight=\"bold\",\n",
    "                        path_effects=[patheffects.withStroke(linewidth=3, foreground=\"white\")]\n",
    "                    )\n",
    "                )\n",
    "        adjust_text(texts, ax=ax)  # no arrows this time\n",
    "\n",
    "    # Plot each reasoner\n",
    "    plot_line_with_values(axes[0], df_owl2vec, \"OWL2Vec*\")\n",
    "    plot_line_with_values(axes[1], df_box2el, \"Box2EL\")\n",
    "    plot_line_with_values(axes[2], df_gnn, \"R-GCN\")\n",
    "\n",
    "    # Create a single legend on the last plot\n",
    "    handles, labels = axes[2].get_legend_handles_labels()\n",
    "    axes[2].legend(handles, labels, title=\"Task\", loc='upper right')\n",
    "    axes[0].legend_.remove()\n",
    "    axes[1].legend_.remove()\n",
    "\n",
    "    # Save and show the plot\n",
    "    save_dir = \"models/results/figures/\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, output_file_name)\n",
    "    title = title.replace(\"Gnn\", \"Statistical\")\n",
    "    title = title.replace(\"Owl2dl-1\", \"OWL2DL-1\")\n",
    "    fig.suptitle(title, fontsize=18)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "\n",
    "def main(ontology_name, noise_type):\n",
    "    df_box2el = get_results_mean(ontology_name, 'box2el', 0)\n",
    "    df_owl2vec = get_results_mean(ontology_name, 'owl2vec', 0)\n",
    "    df_gnn = get_results_mean(ontology_name, 'rgcn_reasoner', 0)\n",
    "    df = pd.concat([df_box2el, df_owl2vec, df_gnn], ignore_index=True)\n",
    "\n",
    "    noise_types = ['random', 'logical', 'gnn']\n",
    "    dfs = [df[df['NoiseType'] == 'None'].assign(NoiseType=noise) for noise in noise_types]\n",
    "    df_no_noise = pd.concat(dfs, ignore_index=True)\n",
    "    df = pd.concat([df, df_no_noise], ignore_index=True)\n",
    "\n",
    "    visualize(df, noise_type, f'{noise_type.capitalize()} Noise - {ontology_name.capitalize()}', f'{ontology_name}_{noise_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4df826",
   "metadata": {},
   "outputs": [],
   "source": [
    "main('family', 'random')\n",
    "main('family', 'gnn')\n",
    "main('family', 'logical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main('pizza_100', 'random')\n",
    "main('pizza_100', 'gnn')\n",
    "main('pizza_100', 'logical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8dad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "main('pizza_250', 'random')\n",
    "main('pizza_250', 'gnn')\n",
    "main('pizza_250', 'logical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc69294",
   "metadata": {},
   "outputs": [],
   "source": [
    "main('OWL2DL-1', 'random')\n",
    "main('OWL2DL-1', 'gnn')\n",
    "main('OWL2DL-1', 'logical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902fb938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def get_results_mean_all_metrics(ontology_name, reasoner, output_file=None):\n",
    "    tasks = [\"Membership\", \"Link Prediction\"]\n",
    "    file_pattern = f\"models/results/{reasoner}/{ontology_name}*.txt\"\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for filepath in glob.glob(file_pattern, recursive=True):\n",
    "        filename = filepath.split(\"\\\\\")[-1]\n",
    "        parts = filename.replace(\".txt\", \"\").split(\"_\")\n",
    "        reasoner_name = f\"{reasoner}\"\n",
    "\n",
    "        if len(parts) == 1 or len(parts) == 2:\n",
    "            ontology = f\"{ontology_name}\"\n",
    "            noise_type = \"None\"\n",
    "            noise_level = 0\n",
    "        elif len(parts) == 3:\n",
    "            ontology, noise_type, noise_level = parts\n",
    "        elif len(parts) == 4:\n",
    "            ontology_1, ontology_2, noise_type, noise_level = parts\n",
    "            ontology = ontology_1 + \"_\" + ontology_2\n",
    "        else:\n",
    "            print(f\"⚠️ Skipping file (unexpected filename): {filename}\")\n",
    "            continue\n",
    "\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        current_task = None\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.rstrip(\":\") in tasks:\n",
    "                current_task = line.rstrip(\":\")\n",
    "            elif line.startswith(\"Mean:\") and current_task:\n",
    "                mean_values = line.replace(\"Mean:\", \"\").split(\"&\")\n",
    "                mean_values = [float(x.strip()) for x in mean_values if x.strip()]\n",
    "                data.append({\n",
    "                    \"Ontology\": ontology,\n",
    "                    \"Reasoner\": reasoner_name,\n",
    "                    \"NoiseType\": noise_type,\n",
    "                    \"NoiseLevel\": noise_level,\n",
    "                    \"Task\": current_task,\n",
    "                    \"Metrics\": mean_values\n",
    "                })\n",
    "                current_task = None\n",
    "\n",
    "    if output_file:\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "            max_metrics_len = max(len(entry[\"Metrics\"]) for entry in data)\n",
    "            headers = [\"Ontology\", \"Reasoner\", \"NoiseType\", \"NoiseLevel\", \"Task\"] + [f\"Metric_{i+1}\" for i in range(max_metrics_len)]\n",
    "            out_f.write(\"\\t\".join(headers) + \"\\n\")\n",
    "\n",
    "            for entry in data:\n",
    "                metrics = entry[\"Metrics\"] + [\"\"] * (max_metrics_len - len(entry[\"Metrics\"]))\n",
    "                row = [\n",
    "                    entry[\"Ontology\"], entry[\"Reasoner\"], entry[\"NoiseType\"], str(entry[\"NoiseLevel\"]), entry[\"Task\"]\n",
    "                ] + [str(m) for m in metrics]\n",
    "                out_f.write(\"\\t\".join(row) + \"\\n\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47705a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_family_owl2vec = get_results_mean_all_metrics(\"family\", \"owl2vec\", output_file=\"models/results/family_owl2vec.txt\")\n",
    "df_family_box2el = get_results_mean_all_metrics(\"family\", \"box2el\", output_file=\"models/results/family_box2el.txt\")\n",
    "df_family_rgcn = get_results_mean_all_metrics(\"family\", \"rgcn_reasoner\", output_file=\"models/results/family_rgcn.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e0ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pizza_100_owl2vec = get_results_mean_all_metrics(\"pizza_100\", \"owl2vec\", output_file=\"models/results/pizza_100_owl2vec.txt\")\n",
    "df_pizza_100_box2el = get_results_mean_all_metrics(\"pizza_100\", \"box2el\", output_file=\"models/results/pizza_100_box2el.txt\")\n",
    "df_pizza_100_rgcn = get_results_mean_all_metrics(\"pizza_100\", \"rgcn_reasoner\", output_file=\"models/results/pizza_100_rgcn.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pizza_250_owl2vec = get_results_mean_all_metrics(\"pizza_250\", \"owl2vec\", output_file=\"models/results/pizza_250_owl2vec.txt\")\n",
    "df_pizza_250_box2el = get_results_mean_all_metrics(\"pizza_250\", \"box2el\", output_file=\"models/results/pizza_250_box2el.txt\")\n",
    "df_pizza_250_rgcn = get_results_mean_all_metrics(\"pizza_250\", \"rgcn_reasoner\", output_file=\"models/results/pizza_250_rgcn.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac33e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OWL2DL1_owl2vec = get_results_mean_all_metrics(\"OWL2DL-1\", \"owl2vec\", output_file=\"models/results/OWL2DL1_owl2vec.txt\")\n",
    "df_OWL2DL1_box2el = get_results_mean_all_metrics(\"OWL2DL-1\", \"box2el\", output_file=\"models/results/OWL2DL1_box2el.txt\")\n",
    "df_OWL2DL1_rgcn = get_results_mean_all_metrics(\"OWL2DL-1\", \"rgcn_reasoner\", output_file=\"models/results/OWL2DL1_rgcn.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
