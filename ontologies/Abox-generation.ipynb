{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import logging\n",
    "from typing import List, Dict, Any, Tuple, Set\n",
    "from owlready2 import ThingClass\n",
    "from owlready2 import get_ontology, Restriction, And, Or, ThingClass, ObjectPropertyClass\n",
    "\n",
    "\n",
    "#logger = logging.getLogger(__name__)\n",
    "\n",
    "# ---------------- SmartAxiomParser remains the same ----------------\n",
    "# (Assume SmartAxiomParser class from previous code is already defined here)\n",
    "\n",
    "# ---------------- Instance Generation Helpers ----------------\n",
    "\n",
    "# ---------------- SmartAxiomParser ----------------\n",
    "class SmartAxiomParser:\n",
    "    def __init__(self, ontology):\n",
    "        self.onto = ontology\n",
    "\n",
    "    def get_class_expressions_with_properties(self, owl_class: ThingClass, debug: bool = False) -> Set[Tuple[Any, Any]]:\n",
    "        expressions = set()\n",
    "        for ancestor in owl_class.mro():\n",
    "            expressions.update(self._parse_expressions(getattr(ancestor, \"is_a\", []), debug))\n",
    "            expressions.update(self._parse_expressions(getattr(ancestor, \"equivalent_to\", []), debug))\n",
    "        if debug:\n",
    "            print(f\"\\nClass expressions with properties for {owl_class.name}:\")\n",
    "            for prop, obj in expressions:\n",
    "                print(f\"Property: {prop}, Object type: {obj}\")\n",
    "        return expressions\n",
    "\n",
    "    def _parse_expressions(self, expressions: List[Any], debug: bool = False) -> Set[Tuple[Any, Any]]:\n",
    "        results = set()\n",
    "        for expr in expressions:\n",
    "            if isinstance(expr, list):\n",
    "                results.update(self._parse_expressions(expr, debug))\n",
    "            elif isinstance(expr, And):\n",
    "                results.update(self._parse_expressions(expr.Classes, debug))\n",
    "            elif isinstance(expr, Or):\n",
    "                for path in expr.Classes:\n",
    "                    results.update(self._parse_expressions([path], debug))\n",
    "            elif isinstance(expr, Restriction):\n",
    "                results.update(self._handle_restriction(expr, debug))\n",
    "        return results\n",
    "\n",
    "    def _handle_restriction(self, restriction: Restriction, debug: bool = False) -> Set[Tuple[Any, Any]]:\n",
    "        prop = restriction.property\n",
    "        value = restriction.value\n",
    "        results = set()\n",
    "        if isinstance(value, Restriction):\n",
    "            nested_results = self._handle_restriction(value, debug)\n",
    "            for _, nested_value in nested_results:\n",
    "                results.add((prop, nested_value))\n",
    "        elif isinstance(value, list):\n",
    "            for v in value:\n",
    "                if isinstance(v, Restriction):\n",
    "                    nested_results = self._handle_restriction(v, debug)\n",
    "                    for _, nested_value in nested_results:\n",
    "                        results.add((prop, nested_value))\n",
    "                else:\n",
    "                    results.add((prop, v))\n",
    "        else:\n",
    "            results.add((prop, value))\n",
    "        if debug:\n",
    "            print(f\"Restriction found: Property = {prop}, Object type = {value}\")\n",
    "        return results\n",
    "\n",
    "def create_individuals_for_class(onto: Any, cls_name: str, count: int) -> List[Tuple[ThingClass, Any]]:\n",
    "    \"\"\"\n",
    "    Create `count` individuals for a given class and its subclasses.\n",
    "    Returns a list of (class_obj, individual_obj) tuples.\n",
    "    \"\"\"\n",
    "    main_class = onto.search_one(iri=f\"*#{cls_name}\")\n",
    "    if main_class is None:\n",
    "        logger.warning(f\"Class '{cls_name}' not found. Skipping.\")\n",
    "        return []\n",
    "    classes = [main_class]\n",
    "    for acls in main_class.subclasses():\n",
    "        if not isinstance(acls, ObjectPropertyClass):\n",
    "            classes.append(acls)\n",
    "    print (\"classes \", classes)\n",
    "    individuals = []\n",
    "\n",
    "    for i in range(count):\n",
    "        cls_to_instantiate = random.choice(classes)\n",
    "        new_individual = cls_to_instantiate(f\"{cls_to_instantiate.name}_{i}\")\n",
    "        individuals.append((cls_to_instantiate, new_individual))\n",
    "        logger.info(f\"Created individual '{new_individual.name}' of class '{cls_to_instantiate.name}'.\")\n",
    "\n",
    "    return individuals\n",
    "\n",
    "def get_required_object_classes(parser: Any, subj_cls_obj: ThingClass) -> List[ThingClass]:\n",
    "    \"\"\"\n",
    "    Use SmartAxiomParser to extract required object classes for a given property.\n",
    "    \"\"\"\n",
    "    expr_props = parser.get_class_expressions_with_properties(subj_cls_obj)\n",
    "    print (expr_props)\n",
    "    #required_obj_classes = [obj for p, obj in expr_props]\n",
    "    return expr_props\n",
    "\n",
    "def assign_relations(onto: Any, parser: Any, instances: Dict[str, List[Tuple[Any, Any]]],\n",
    "                     relation_config: List[Tuple[str, str, str]]):\n",
    "    \"\"\"\n",
    "    Assign object properties to individuals based on relation_config and class restrictions.\n",
    "    \"\"\"\n",
    "    instance_counter = {}\n",
    "\n",
    "    for subj_cls_name, prop_name, obj_class_name in relation_config:\n",
    "        if subj_cls_name not in instances:\n",
    "            continue\n",
    "        subjects = instances[subj_cls_name]\n",
    "        rel = onto.search_one(iri=f\"*{prop_name}\")\n",
    "        if rel is None:\n",
    "            continue\n",
    "\n",
    "        for subj_cls_obj, subj_individual in subjects:\n",
    "            required_obj_classes = get_required_object_classes(parser, subj_cls_obj)\n",
    "            obj_cls_to_use = None\n",
    "            for p, obj in required_obj_classes:\n",
    "                if p == rel:\n",
    "                    print (\"obj_cls_to_use\", p, obj)\n",
    "                    if isinstance(obj, Or):\n",
    "                        continue\n",
    "                    obj_cls_to_use = obj\n",
    "                    \n",
    "            if obj_cls_to_use == None:\n",
    "                # Fallback to prop_name-based search if no restrictions exist\n",
    "                obj_cls_to_use = onto.search_one(iri=f\"*#{obj_class_name}\")\n",
    "                print (\"obj_cls_to_use\", obj_cls_to_use)\n",
    "\n",
    "            print (\"obj_cls_to_use\", obj_cls_to_use)\n",
    "            obj_cls_name = obj_cls_to_use.name\n",
    "            # Reuse existing instances or create new dynamic individual\n",
    "            if obj_cls_name in instances and instances[obj_cls_name]:\n",
    "                new_obj_individual = random.choice(instances[obj_cls_name])[1]\n",
    "            else:\n",
    "                instance_counter[obj_cls_name] = instance_counter.get(obj_cls_name, 0) + 1\n",
    "                new_obj_individual = obj_cls_to_use(f\"{obj_cls_name}_dynamic_{instance_counter[obj_cls_name]}\")\n",
    "                instances.setdefault(obj_cls_name, []).append((obj_cls_to_use, new_obj_individual))\n",
    "\n",
    "            rel[subj_individual].append(new_obj_individual)\n",
    "            logger.info(f\"Linked '{subj_individual.name}' -> '{new_obj_individual.name}' via '{prop_name}'.\")\n",
    "\n",
    "# ---------------- Main Instance Generation ----------------\n",
    "\n",
    "def generate_instances(onto: Any, class_config: Dict[str, int], relation_config: List[Tuple[str, str, str]]) -> Dict[str, List[Tuple[Any, Any]]]:\n",
    "    \"\"\"\n",
    "    Main function to generate individuals and assign relations.\n",
    "    \"\"\"\n",
    "    instances: Dict[str, List[Tuple[Any, Any]]] = {}\n",
    "    parser = SmartAxiomParser(onto)\n",
    "\n",
    "    # Step 1: Create individuals\n",
    "    for cls_name, count in class_config.items():\n",
    "        individuals = create_individuals_for_class(onto, cls_name, count)\n",
    "        instances.setdefault(cls_name, []).extend(individuals)\n",
    "\n",
    "    # Step 2: Assign relations\n",
    "    assign_relations(onto, parser, instances, relation_config)\n",
    "\n",
    "    return instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Replace with your class\n",
    "dataset_name =\"OWL2DL-1\"\n",
    "tbox_path: str = f\"../../data/tbox/{dataset_name}_TBOX.owl\"\n",
    "onto = get_ontology(tbox_path).load()\n",
    "my_class = onto.Person  \n",
    "parser = SmartAxiomParser(onto)\n",
    "\n",
    "for aclass in my_class.subclasses():\n",
    "    expr_props = parser.get_class_expressions_with_properties(aclass, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlready2 import get_ontology, sync_reasoner_pellet, default_world, Restriction, And, Or # Import all necessary owlready2 functions/classes explicitly\n",
    "from rdflib import Graph # Used for RDF graph manipulation and counting triples\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "# Assuming the user's previously defined helper functions are available here:\n",
    "# from your_utils_module import generate_instances # Example import if in a separate file\n",
    "\n",
    "# --- Logging Setup ---\n",
    "# Set up a basic logger for feedback during script execution\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG) \n",
    "# Note: For production use, you would typically configure a handler (like StreamHandler)\n",
    "# logging.basicConfig(level=logging.INFO) \n",
    "\n",
    "# --- Configuration ---\n",
    "# Define the dataset name. Only one should be uncommented at a time.\n",
    "# The selected dataset name determines the TBOX file to load.\n",
    "# dataset_name = \"pizza\"\n",
    "#dataset_name = \"pizza\"\n",
    "dataset_name = \"OWL2DL-1\"\n",
    "\n",
    "logger.info(f\"Configuration set for dataset: **{dataset_name}**\")\n",
    "\n",
    "# --- Instance Generation Configuration (Abox) ---\n",
    "\n",
    "# Define the set of configurations for different experiments.\n",
    "# The active configuration is selected based on `dataset_name`.\n",
    "\n",
    "# Configuration for the 'pizza' ontology\n",
    "pizza_config: Dict[str, Any] = {\n",
    "    \"class_config\": {\n",
    "        \"NamedPizza\": 100  \n",
    "    },\n",
    "    \"relation_config\": {\n",
    "        (\"NamedPizza\", \"hasTopping\", \"PizzaTopping\"): 10\n",
    "}\n",
    "}\n",
    "\n",
    "# Configuration for the 'family' ontology (Currently active)\n",
    "family_config: Dict[str, Any] = {\n",
    "    \"class_config\": {\n",
    "        \"Person\": 10  \n",
    "    },\n",
    "    \"relation_config\": [\n",
    "        (\"Person\", \"hasFather\", \"Person\"),\n",
    "        (\"Person\", \"hasMother\", \"Person\"),\n",
    "        (\"Person\", \"hasSex\", \"Sex\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Configuration for the 'University' ontology\n",
    "university_config: Dict[str, Any] = {\n",
    "    \"class_config\": {\n",
    "        \"University\": 20,\n",
    "        \"Department\": 10,\n",
    "        \"Person\": 100,\n",
    "        \"Course\": 20\n",
    "    },\n",
    "    \"relation_config\": [\n",
    "        (\"University\", \"hasDepartment\", \"Department\"),\n",
    "        (\"Person\", \"hasDoctoralDegreeFrom\", \"University\"),\n",
    "        (\"Person\", \"teachesCourse\", \"Course\"),\n",
    "        (\"Person\", \"takesCourse\", \"Course\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Select the active configuration based on the dataset_name variable\n",
    "if dataset_name == \"pizza\":\n",
    "    active_config = pizza_config\n",
    "elif dataset_name == \"family\":\n",
    "    active_config = family_config\n",
    "elif dataset_name == \"OWL2DL-1\":\n",
    "    # Assuming OWL2DL-1 uses the university config for this example\n",
    "    active_config = university_config \n",
    "else:\n",
    "    raise ValueError(f\"No configuration defined for dataset '{dataset_name}'.\")\n",
    "\n",
    "class_config: Dict[str, int] = active_config[\"class_config\"]\n",
    "relation_config: List[Tuple[str, str, str]] = active_config[\"relation_config\"]\n",
    "\n",
    "# ==========================================================\n",
    "# 1. Load Ontology (TBox)\n",
    "# ==========================================================\n",
    "# Construct the path to the TBox (Terminological Box) file.\n",
    "tbox_path: str = f\"../../data/tbox/{dataset_name}_TBOX.owl\"\n",
    "\n",
    "try:\n",
    "    # Get the ontology object and load the TBox from the specified path.\n",
    "    onto = get_ontology(tbox_path).load()\n",
    "    logger.info(f\"Loaded ontology successfully: **{onto.base_iri}** from path: {tbox_path}\")\n",
    "except FileNotFoundError:\n",
    "    logger.error(f\"Error: Ontology file not found at {tbox_path}\")\n",
    "    raise\n",
    "\n",
    "# ==========================================================\n",
    "# 2. Generate Individuals (ABox)\n",
    "# ==========================================================\n",
    "# Use the previously defined `generate_instances` function to create individuals \n",
    "# (ABox assertions) and establish initial relations based on the selected configuration.\n",
    "# This function populates the ontology object (`onto`) in memory.\n",
    "logger.info(\"Generating individuals and initial ABox relations...\")\n",
    "# NOTE: The generate_instances function must be accessible/imported.\n",
    "try:\n",
    "    instances: Dict[str, List[Tuple[Any, Any]]] = generate_instances(onto, class_config, relation_config)\n",
    "    logger.info(f\"Finished generating ABox. Total classes instantiated: {len(instances)}\")\n",
    "except NameError:\n",
    "    logger.error(\"The `generate_instances` function is not defined or imported.\")\n",
    "    raise\n",
    "\n",
    "# ==========================================================\n",
    "# 3. Save and Analyze Ontology BEFORE Reasoning\n",
    "# ==========================a================================\n",
    "# Save the ontology state *before* running the reasoner.\n",
    "temp_file_before: str = f\"../../data/abox/{dataset_name}_ABox.owl\"\n",
    "onto.save(temp_file_before, format=\"rdfxml\")\n",
    "logger.info(f\"Ontology state saved to '{temp_file_before}' for pre-reasoning analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
