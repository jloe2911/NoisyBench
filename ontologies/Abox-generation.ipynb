{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import subprocess\n",
    "import logging\n",
    "import random\n",
    "from typing import List, Dict, Any, Tuple, Set # Import types for better type hinting\n",
    "# Assuming Restriction, And, Or are imported from owlready2 for the original logic\n",
    "# If not available, these imports will need to be added:\n",
    "# from owlready2.expression import Restriction, And, Or \n",
    "# from owlready2 import Thing, Ontology, Property # Add other necessary owlready2 imports\n",
    "\n",
    "import logging\n",
    "\n",
    "# --- Simple Logger Setup to File ---\n",
    "\n",
    "# Define the log file name\n",
    "LOG_FILE_PATH = 'app_output.log'\n",
    "\n",
    "# Configure the root logger to output to the file\n",
    "# filemode='w' overwrites the file each time; use 'a' to append (default is 'a' in Python 3.9+)\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE_PATH,\n",
    "    level=logging.DEBUG, # Only messages of INFO level and higher are saved\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# --- Logging Messages ---\n",
    "\n",
    "\n",
    "# --- Logging Setup ---\n",
    "# Configure a logger for this module\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- Utility Functions for Ontology Restriction Parsing ---\n",
    "\n",
    "# Refactor the restriction parsing function for better encapsulation and standard practices.\n",
    "\n",
    "def _extract_classes_from_restriction_expression(expr: Any, prop: Any, required_toppings: Set[Any]) -> None:\n",
    "    \"\"\"\n",
    "    Recursively extracts required OWL classes from restriction expressions \n",
    "    (e.g., Restriction, And, Or, or lists/tuples of expressions) linked by a specific property.\n",
    "\n",
    "    This internal helper function populates the 'required_toppings' set.\n",
    "\n",
    "    Args:\n",
    "        expr (Any): The current OWL expression to process (e.g., Restriction, And, Or, list).\n",
    "        prop (Any): The target property object (e.g., 'has_topping').\n",
    "        required_toppings (Set[Any]): The set to add the required OWL classes (values) to.\n",
    "    \"\"\"\n",
    "    # Case 1: Direct Restriction (e.g., 'Only' or 'Some' restrictions)\n",
    "    # Check if the expression is a Restriction and if its property matches the target property.\n",
    "    if isinstance(expr, Restriction) and getattr(expr, \"property\", None) == prop:\n",
    "        # The 'value' attribute of the restriction holds the class being restricted.\n",
    "        # Check if the value has a 'name' attribute, typical of an OWL class object.\n",
    "        if hasattr(expr.value, \"name\"):\n",
    "            logger.debug(f\"Found required restriction class: {expr.value.name}\")\n",
    "            required_toppings.add(expr.value)\n",
    "    \n",
    "    # Case 2: Conjunction (And) or Disjunction (Or)\n",
    "    # Recursively process sub-expressions within logical operators.\n",
    "    elif isinstance(expr, (And, Or)):\n",
    "        # Owlready2 stores sub-expressions in the 'Classes' attribute.\n",
    "        for subexpr in expr.Classes:\n",
    "            _extract_classes_from_restriction_expression(subexpr, prop, required_toppings)\n",
    "    \n",
    "    # Case 3: A list or tuple of expressions\n",
    "    # Handle cases where expressions are stored in an iterable (common in owlready2).\n",
    "    elif isinstance(expr, (list, tuple)):\n",
    "        for subexpr in expr:\n",
    "            _extract_classes_from_restriction_expression(subexpr, prop, required_toppings)\n",
    "    \n",
    "    # Otherwise, ignore the expression.\n",
    "\n",
    "def properties_from_restrictions(sub_class: Any, prop: Any) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Extracts OWL classes required by restrictions on a given OWL class ('sub_class') \n",
    "    for a specific property ('prop'). It handles nested logical expressions.\n",
    "\n",
    "    Args:\n",
    "        sub_class (Any): The OWL class object whose restrictions are being examined.\n",
    "        prop (Any): The target property object (e.g., 'has_topping').\n",
    "\n",
    "    Returns:\n",
    "        List[Any]: A list of OWL class objects that are required targets \n",
    "                   of the property restrictions.\n",
    "    \"\"\"\n",
    "    required_toppings: Set[Any] = set()\n",
    "\n",
    "    # The `is_a` attribute contains the class hierarchy and restrictions defined on the class.\n",
    "    for eq in sub_class.is_a:\n",
    "        logger.debug(f\"Processing `is_a` expression: {eq}\")\n",
    "        # Extract restrictions from the main expression\n",
    "        _extract_classes_from_restriction_expression(eq, prop, required_toppings)\n",
    "        \n",
    "        # Check for nested restrictions, though `is_a` often contains the full hierarchy directly.\n",
    "        # The original code's check `if eq.is_a is not None` might be redundant \n",
    "        # but is kept here to match the original intent of handling complex structures.\n",
    "        if hasattr(eq, 'is_a') and eq.is_a is not None:\n",
    "             _extract_classes_from_restriction_expression(eq.is_a, prop, required_toppings)\n",
    "\n",
    "    return list(required_toppings)\n",
    "\n",
    "# --- Core Instance Generation Function ---\n",
    "\n",
    "def generate_instances(onto: Any, class_config: Dict[str, int], relation_config: List[Tuple[str, str, str]]) -> Dict[str, List[Tuple[Any, Any]]]:\n",
    "    \"\"\"\n",
    "    Generic instance generator for an ontology, populating classes and relations.\n",
    "\n",
    "    The generator first creates a specified number of individuals for each class \n",
    "    (potentially across its subclasses) and then attempts to link them based on \n",
    "    explicit relations defined in 'relation_config' and implicit constraints (restrictions).\n",
    "    \n",
    "    Args:\n",
    "        onto (Any): The owlready2 Ontology object to populate.\n",
    "        class_config (Dict[str, int]): Mapping of class names -> number of individuals to create.\n",
    "        relation_config (List[Tuple[str, str, str]]): List of tuples defining relation patterns:\n",
    "            (subject_class_name, property_name, object_class_name - Note: obj_class is not used \n",
    "             in the current logic, as it's driven by restrictions).\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, List[Tuple[Any, Any]]]: A dictionary mapping class names to lists \n",
    "                                          of (subclass_object, individual_object) tuples.\n",
    "    \"\"\"\n",
    "    # Use the 'with onto:' context manager to ensure all changes are applied to the ontology\n",
    "    # (especially important for `owlready2` operations).\n",
    "    with onto:\n",
    "        # Store individuals created, mapping Class Name -> List of (Subclass, Individual)\n",
    "        instances: Dict[str, List[Tuple[Any, Any]]] = {}\n",
    "        instance_counter = {} # To track counter for newly created objects not in config\n",
    "\n",
    "        # 1. Create instances for each class specified in the config\n",
    "        logger.info(\"--- Creating Individuals ---\")\n",
    "        for cls_name, n in class_config.items():\n",
    "            # Search for the main class object in the ontology\n",
    "            main_class = onto.search_one(iri=f\"*{cls_name}\")\n",
    "            if main_class is None:\n",
    "                logger.warning(f\"Main class '{cls_name}' not found in ontology. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Get all direct and indirect subclasses of the main class\n",
    "            classes = list(main_class.subclasses())\n",
    "            \n",
    "            # If no subclasses are found, the main class itself is the target class for instantiation\n",
    "            if not classes:\n",
    "                classes = [main_class]\n",
    "            \n",
    "            logger.info(f\"Instantiating {n} individuals for {cls_name} across {len(classes)} subclasses.\")\n",
    "\n",
    "            for i in range(n):\n",
    "                # Choose a random subclass for instantiation\n",
    "                cls_to_instantiate = random.choice(classes)\n",
    "                \n",
    "                # Use the main class name as the key in the instances dictionary\n",
    "                if cls_name not in instances:\n",
    "                    instances[cls_name] = []\n",
    "                \n",
    "                # Create the individual. The name is constructed using the subclass name and an index.\n",
    "                # E.g., main_class(f\"SubclassName_0\") creates an instance of main_class that is\n",
    "                # also an instance of SubclassName, with the given name.\n",
    "                new_individual = main_class(f\"{cls_to_instantiate.name}_{i}\")\n",
    "                \n",
    "                # Store the (Subclass_Object, Individual_Object) tuple\n",
    "                instances[cls_name].append((cls_to_instantiate, new_individual))\n",
    "                logger.debug(f\"Created individual '{new_individual.name}' of class '{cls_to_instantiate.name}'.\")\n",
    "\n",
    "        logger.info(\"Total individuals created across configured classes.\")\n",
    "        logger.debug(f\"Instances: {instances}\")\n",
    "\n",
    "        # 2. Randomly assign relations based on configuration and class restrictions\n",
    "        logger.info(\"--- Assigning Relations ---\")\n",
    "        # The 'obj_class' in relation_config is often ignored here, as the actual object class\n",
    "        # is determined by the `properties_from_restrictions` function based on the subject's definition.\n",
    "        for subj_cls_name, prop_name, _ in relation_config:\n",
    "            if subj_cls_name not in instances:\n",
    "                logger.warning(f\"Subject class '{subj_cls_name}' not instantiated. Skipping relation for '{prop_name}'.\")\n",
    "                continue\n",
    "\n",
    "            subjects: List[Tuple[Any, Any]] = instances[subj_cls_name]\n",
    "            \n",
    "            # Search for the property object\n",
    "            rel = onto.search_one(iri=f\"*{prop_name}\")\n",
    "            if rel is None:\n",
    "                logger.warning(f\"Property '{prop_name}' not found in ontology. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            logger.info(f\"Processing relation '{prop_name}' for subjects of class '{subj_cls_name}'.\")\n",
    "            \n",
    "            for subj_cls_obj, subj_individual in subjects:\n",
    "                # Determine the required object classes based on the subject's class restrictions\n",
    "                required_obj_classes = properties_from_restrictions(subj_cls_obj, rel)\n",
    "                \n",
    "                logger.debug(f\"Subject class '{subj_cls_obj.name}' requires objects of classes: \"\n",
    "                             f\"{[cls.name for cls in required_obj_classes]} for property '{prop_name}'.\")\n",
    "\n",
    "                # The original code's logic is to apply the relation for *all* found restrictions\n",
    "                for obj_cls_to_use in required_obj_classes:\n",
    "                    # Check if instances of the required object class already exist\n",
    "                    obj_cls_name = obj_cls_to_use.name\n",
    "                    \n",
    "                    if obj_cls_name in instances and instances[obj_cls_name]:\n",
    "                        # Choose a random existing individual of the required class as the object\n",
    "                        # We select the [1] element of the tuple, which is the individual object.\n",
    "                        new_obj_individual = random.choice(instances[obj_cls_name])[1]\n",
    "                        logger.debug(f\"Using existing object '{new_obj_individual.name}' of class '{obj_cls_name}'.\")\n",
    "                    else:\n",
    "                        # If no existing instance is found, create a new one dynamically\n",
    "                        # This assumes the required object class (obj_cls_to_use) can be called\n",
    "                        # to create an instance, which is typical for owlready2 classes.\n",
    "                        instance_counter[obj_cls_name] = instance_counter.get(obj_cls_name, 0) + 1\n",
    "                        i = instance_counter[obj_cls_name]\n",
    "                        new_obj_individual = obj_cls_to_use(f\"{obj_cls_name}_dynamic_{i}\")\n",
    "                        \n",
    "                        # Store the newly created object (not part of the initial config)\n",
    "                        if obj_cls_name not in instances:\n",
    "                            instances[obj_cls_name] = []\n",
    "                        instances[obj_cls_name].append((obj_cls_to_use, new_obj_individual))\n",
    "                        logger.debug(f\"Created new dynamic object '{new_obj_individual.name}' of class '{obj_cls_name}'.\")\n",
    "                    \n",
    "                    # Apply the relation: prop[subject] = object\n",
    "                    # For object properties, this sets a link. For functional properties, this may overwrite.\n",
    "                    rel[subj_individual].append(new_obj_individual)\n",
    "                    \n",
    "                    # Store the relation in the instances dict using the property name as the key\n",
    "                    # NOTE: This line `instances[prop_name] = rel[subj_individual]` seems non-standard\n",
    "                    # as it overwrites the 'prop_name' key in the `instances` dict in every iteration. \n",
    "                    # It's kept for functional equivalence but may be indicative of a logic error \n",
    "                    # in how relations are tracked. A separate dict for relations is usually better.\n",
    "                    # This line is not essential for the ontology population itself.\n",
    "                    # instances[prop_name] = rel[subj_individual] \n",
    "                    \n",
    "                    logger.info(f\"Linked '{subj_individual.name}' to '{new_obj_individual.name}' via '{prop_name}'.\")\n",
    "\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlready2 import get_ontology, sync_reasoner_pellet, default_world, Restriction, And, Or # Import all necessary owlready2 functions/classes explicitly\n",
    "from rdflib import Graph # Used for RDF graph manipulation and counting triples\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "# Assuming the user's previously defined helper functions are available here:\n",
    "# from your_utils_module import generate_instances # Example import if in a separate file\n",
    "\n",
    "# --- Logging Setup ---\n",
    "# Set up a basic logger for feedback during script execution\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO) \n",
    "# Note: For production use, you would typically configure a handler (like StreamHandler)\n",
    "# logging.basicConfig(level=logging.INFO) \n",
    "\n",
    "# --- Configuration ---\n",
    "# Define the dataset name. Only one should be uncommented at a time.\n",
    "# The selected dataset name determines the TBOX file to load.\n",
    "# dataset_name = \"pizza\"\n",
    "dataset_name = \"pizza\"\n",
    "#dataset_name = \"OWL2DL-1\"\n",
    "\n",
    "logger.info(f\"Configuration set for dataset: **{dataset_name}**\")\n",
    "\n",
    "# --- Instance Generation Configuration (Abox) ---\n",
    "\n",
    "# Define the set of configurations for different experiments.\n",
    "# The active configuration is selected based on `dataset_name`.\n",
    "\n",
    "# Configuration for the 'pizza' ontology\n",
    "pizza_config: Dict[str, Any] = {\n",
    "    \"class_config\": {\n",
    "        \"NamedPizza\": 1000  \n",
    "    },\n",
    "    \"relation_config\": [\n",
    "        (\"NamedPizza\", \"hasTopping\", \"PizzaTopping\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Configuration for the 'family' ontology (Currently active)\n",
    "family_config: Dict[str, Any] = {\n",
    "    \"class_config\": {\n",
    "        \"Person\": 10  \n",
    "    },\n",
    "    \"relation_config\": [\n",
    "        (\"Person\", \"hasFather\", \"Person\"),\n",
    "        (\"Person\", \"hasMother\", \"Person\"),\n",
    "        (\"Person\", \"hasSex\", \"Sex\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Configuration for the 'University' ontology\n",
    "university_config: Dict[str, Any] = {\n",
    "    \"class_config\": {\n",
    "        \"University\": 30,\n",
    "        \"Person\": 100\n",
    "    },\n",
    "    \"relation_config\": [\n",
    "        (\"University\", \"hasDepartment\", \"Department\"),\n",
    "        (\"Person\", \"hasDoctoralDegreeFrom\", \"University\"),\n",
    "        (\"Person\", \"teachesCourse\", \"Course\"),\n",
    "        (\"Person\", \"takesCourse\", \"Course\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Select the active configuration based on the dataset_name variable\n",
    "if dataset_name == \"pizza\":\n",
    "    active_config = pizza_config\n",
    "elif dataset_name == \"family\":\n",
    "    active_config = family_config\n",
    "elif dataset_name == \"OWL2DL-1\":\n",
    "    # Assuming OWL2DL-1 uses the university config for this example\n",
    "    active_config = university_config \n",
    "else:\n",
    "    raise ValueError(f\"No configuration defined for dataset '{dataset_name}'.\")\n",
    "\n",
    "class_config: Dict[str, int] = active_config[\"class_config\"]\n",
    "relation_config: List[Tuple[str, str, str]] = active_config[\"relation_config\"]\n",
    "\n",
    "# ==========================================================\n",
    "# 1. Load Ontology (TBox)\n",
    "# ==========================================================\n",
    "# Construct the path to the TBox (Terminological Box) file.\n",
    "tbox_path: str = f\"../ontologies/{dataset_name}_TBOX.owl\"\n",
    "\n",
    "try:\n",
    "    # Get the ontology object and load the TBox from the specified path.\n",
    "    onto = get_ontology(tbox_path).load()\n",
    "    logger.info(f\"Loaded ontology successfully: **{onto.base_iri}** from path: {tbox_path}\")\n",
    "except FileNotFoundError:\n",
    "    logger.error(f\"Error: Ontology file not found at {tbox_path}\")\n",
    "    raise\n",
    "\n",
    "# ==========================================================\n",
    "# 2. Generate Individuals (ABox)\n",
    "# ==========================================================\n",
    "# Use the previously defined `generate_instances` function to create individuals \n",
    "# (ABox assertions) and establish initial relations based on the selected configuration.\n",
    "# This function populates the ontology object (`onto`) in memory.\n",
    "logger.info(\"Generating individuals and initial ABox relations...\")\n",
    "# NOTE: The generate_instances function must be accessible/imported.\n",
    "try:\n",
    "    instances: Dict[str, List[Tuple[Any, Any]]] = generate_instances(onto, class_config, relation_config)\n",
    "    logger.info(f\"Finished generating ABox. Total classes instantiated: {len(instances)}\")\n",
    "except NameError:\n",
    "    logger.error(\"The `generate_instances` function is not defined or imported.\")\n",
    "    raise\n",
    "\n",
    "# ==========================================================\n",
    "# 3. Save and Analyze Ontology BEFORE Reasoning\n",
    "# ==========================================================\n",
    "# Save the ontology state *before* running the reasoner.\n",
    "temp_file_before: str = f\"{dataset_name}_withABox.owl\"\n",
    "onto.save(temp_file_before, format=\"rdfxml\")\n",
    "logger.info(f\"Ontology state saved to '{temp_file_before}' for pre-reasoning analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
