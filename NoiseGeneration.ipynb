{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761fa5f2-c0ad-4fea-84bc-6ecbcf759d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import rdflib\n",
    "from rdflib import URIRef, Literal, Namespace, RDFS, BNode\n",
    "from owlready2 import get_ontology\n",
    "\n",
    "from src.utils import *\n",
    "from src.gnn import *\n",
    "from src.sparql_queries import *\n",
    "from src.noise import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f479add1-d4dd-44ff-9119-cd18dd1edd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f51ef75-efba-4f30-8032-42ed4b0fc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = 'OWL2DL-1'\n",
    "dataset_name = 'family'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7b16e0-0fa3-4d0a-988d-4d2f1bc3cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == 'family':\n",
    "    uri = Namespace(\"http://www.example.com/genealogy.owl#\")\n",
    "elif dataset_name.startswith('OWL2DL-'):\n",
    "    uri = Namespace(\"https://kracr.iiitd.edu.in/OWL2Bench#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df7d31-b741-44b4-a997-e17df3218285",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182adee3-c4ac-4a76-9897-5b17c7f42b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = rdflib.Graph()\n",
    "g.parse(f'datasets/{dataset_name}.owl', format='xml')\n",
    "num_triples = len(g)\n",
    "print(f'Triplets found in {dataset_name}.owl: %d' % num_triples)\n",
    "\n",
    "g_no_noise = rdflib.Graph()\n",
    "g_no_noise.parse(f'datasets/{dataset_name}_train.owl', format='turtle')\n",
    "num_triples_train = len(g_no_noise)\n",
    "print(f'Triplets found in {dataset_name}.owl: %d' % num_triples_train)\n",
    "\n",
    "ontology = get_ontology(f'datasets/{dataset_name}.owl').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd34f1e-e8ed-41cb-ade2-598e51112aba",
   "metadata": {},
   "source": [
    "# 2. GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d2d9a-ca9a-49bc-a6ce-de64cb017415",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, nodes, nodes_dict, relations, relations_dict = get_data(g_no_noise)\n",
    "nodes_dict_rev = {value: key for key, value in nodes_dict.items()}\n",
    "relations_dict_rev = {value: key for key, value in relations_dict.items()}\n",
    "data = split_edges(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a71d9-df0a-4987-a2ad-eded19f4b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c27ccc-782b-4e6f-813f-10a72e01f989",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad75650-5fe6-4014-be3b-8c90272091bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "model = GNN(device, len(nodes), len(relations))\n",
    "\n",
    "for epoch in range(10+1):\n",
    "    loss = model._train(data.to(device))\n",
    "    print(f'Epoch: {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "torch.save(model, f'models/RGCN_{dataset_name}')\n",
    "et = time.time()\n",
    "elapsed_time = et - st\n",
    "print(f'Run time: {elapsed_time:.0f} seconds, {elapsed_time/60:.0f} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3695fb2-fc34-4c40-acec-10cf70f9a7e9",
   "metadata": {},
   "source": [
    "**Eval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477909fa-bce0-499c-bd3a-98f42897aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(f'models/RGCN_{dataset_name}')\n",
    "# mrr, mean_rank, median_rank, hits_at_5, hits_at_10 = model._eval(data.to(device))\n",
    "# print(f'MRR: {mrr:.3f}, Mean Rank: {mean_rank:.3f}, Median Rank: {median_rank:.3f}, Hits@5: {hits_at_5:.3f}, Hits@10: {hits_at_10:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e038ffe5-3423-49df-bd62-f69964b062d4",
   "metadata": {},
   "source": [
    "# 3. Noise Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae62b8-d00d-4593-b777-cbc253abf2e0",
   "metadata": {},
   "source": [
    "## 3.1. GNN: we add k triples with a low prediction score to the ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4dcc0c-2c24-499b-a3b3-77bc5814aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_triples_gnn(g_no_noise, data, noise_percentage):\n",
    "    max_triples = int((noise_percentage * len(g_no_noise)) / len(relations_dict_rev))\n",
    "    \n",
    "    noisy_g_gnn = rdflib.Graph()\n",
    "    new_g_gnn = copy_graph(g_no_noise)\n",
    "    \n",
    "    for key, _ in tqdm(relations_dict_rev.items()): \n",
    "        mask = data.edge_type == key\n",
    "        edge_index = torch.tensor([data.edge_index[0, mask].tolist(), data.edge_index[1, mask].tolist()])\n",
    "        edge_type = data.edge_type[mask]\n",
    "\n",
    "        output = model.model.encode(edge_index.to(model.device), edge_type.to(model.device))\n",
    "\n",
    "        link_pred_scores = torch.matmul(output, output.T)\n",
    "        output_norm = torch.norm(output, dim=1, keepdim=True)\n",
    "        link_pred_scores_norm = link_pred_scores / (output_norm * output_norm.T)\n",
    "\n",
    "        link_pred_scores_norm[edge_index[0, :], edge_index[1, :]] = 1\n",
    "\n",
    "        _, topk_indices = torch.topk(link_pred_scores_norm.flatten(), max_triples * 2, largest=False)\n",
    "        row_indices = topk_indices // link_pred_scores_norm.size(1)\n",
    "        col_indices = topk_indices % link_pred_scores_norm.size(1)\n",
    "\n",
    "        valid_indices_mask = row_indices < col_indices\n",
    "        row_indices = row_indices[valid_indices_mask]\n",
    "        col_indices = col_indices[valid_indices_mask]\n",
    "\n",
    "        node1_lst = [nodes_dict_rev[row.item()] for row in row_indices]\n",
    "        node2_lst = [nodes_dict_rev[col.item()] for col in col_indices]\n",
    "        edge_type_uri = relations_dict_rev[key]\n",
    "\n",
    "        for s, o in zip(node1_lst, node2_lst):\n",
    "            existing_triples = list(g_no_noise.triples((None, URIRef(edge_type_uri), None)))\n",
    "            if existing_triples:\n",
    "                triple_to_corrupt = random.choice(existing_triples)\n",
    "                subject, predicate, object = triple_to_corrupt \n",
    "\n",
    "                if random.choice([True, False]):\n",
    "                    corrupted_triple = (s, predicate, object)\n",
    "                else:\n",
    "                    corrupted_triple = (subject, predicate, o)\n",
    "\n",
    "                if corrupted_triple not in g_no_noise:\n",
    "                    noisy_g_gnn.add(corrupted_triple)\n",
    "                    new_g_gnn.add(corrupted_triple)\n",
    "\n",
    "    return noisy_g_gnn, new_g_gnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da772b78-efc7-4218-867e-fce6407fae7a",
   "metadata": {},
   "source": [
    "## 3.2. Random: we add k random triples to the ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ff7cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_triples_random(g_no_noise, noise_percentage):\n",
    "    max_triples = int(noise_percentage * len(g_no_noise)) \n",
    "\n",
    "    noisy_g_random = rdflib.Graph()\n",
    "    new_g_random = copy_graph(g_no_noise)\n",
    "    num_triples = 0\n",
    "\n",
    "    subjects = list(set(g_no_noise.subjects()))\n",
    "    objects = list(set(g_no_noise.objects()))\n",
    "    triples_list = list(g_no_noise)\n",
    "\n",
    "    while num_triples < max_triples:\n",
    "        triple = random.choice(triples_list)\n",
    "        s, p, o = triple\n",
    "\n",
    "        if random.choice([True, False]):  \n",
    "            new_s = random.choice(subjects)\n",
    "            corrupted_triple = (new_s, p, o)\n",
    "        else:  \n",
    "            new_o = random.choice(objects)\n",
    "            corrupted_triple = (s, p, new_o)\n",
    "\n",
    "        if corrupted_triple not in g_no_noise:\n",
    "            noisy_g_random.add(corrupted_triple)\n",
    "            new_g_random.add(corrupted_triple)\n",
    "            num_triples += 1\n",
    "    return noisy_g_random, new_g_random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc41e03-83f1-47a9-bb9e-db0f20d6fe18",
   "metadata": {},
   "source": [
    "## 3.3. DL: we add individuals to the ontology that belong to disjoint classes/properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982897fe-4e91-41f7-be06-d4066d0bdc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_disjoint_classes = get_disjoint_classes(ontology)\n",
    "all_disjoint_properties = get_disjoint_properties(ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e422d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_disjoint_axioms(g, g_no_noise, all_disjoint_classes, all_disjoint_properties, uri, noise_percentage):    \n",
    "    # max_triples = int((noise_percentage * len(g_no_noise))/2)\n",
    "    max_triples = int(noise_percentage * len(g_no_noise))\n",
    "\n",
    "    noisy_g_disjoint = rdflib.Graph()\n",
    "    noisy_g_disjoint += add_noise_disjoint_classes(g_no_noise, max_triples, all_disjoint_classes, uri)\n",
    "    # noisy_g_disjoint += add_noise_disjoint_properties(g, g_no_noise, max_triples, all_disjoint_properties, uri)\n",
    "\n",
    "    new_g_disjoint = copy_graph(g_no_noise)\n",
    "    new_g_disjoint += add_noise_disjoint_classes(g_no_noise, max_triples, all_disjoint_classes, uri)\n",
    "    # new_g_disjoint += add_noise_disjoint_properties(g, g_no_noise, max_triples, all_disjoint_properties, uri)\n",
    "    return noisy_g_disjoint, new_g_disjoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7d925",
   "metadata": {},
   "source": [
    "## 3.4. Violate range/domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eea773",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_test = rdflib.Graph()\n",
    "g_test.parse(f'datasets/{dataset_name}_test.owl', format='xml')\n",
    "\n",
    "possible_predicates = get_possible_predicates(g)\n",
    "possible_predicates = [URIRef(x) for x in possible_predicates]\n",
    "\n",
    "possible_predicates = list(set(possible_predicates) & set(set(g_test.predicates())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_domain_info = {}\n",
    "for subj, pred, obj in g:\n",
    "    if pred == RDFS.domain:\n",
    "        property = subj\n",
    "        domain = obj\n",
    "        if not isinstance(domain, BNode):  \n",
    "            range_domain_info[property] = {\"domain\": domain}\n",
    "    elif pred == RDFS.range:\n",
    "        property = subj\n",
    "        range = obj\n",
    "        if not isinstance(range, BNode): \n",
    "            if property not in range_domain_info:\n",
    "                range_domain_info[property] = {}\n",
    "            range_domain_info[property][\"range\"] = range\n",
    "\n",
    "range_domain_info = {k: v for k, v in range_domain_info.items() if k in possible_predicates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c375d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = [cls for cls in g.subjects(RDF.type, OWL.Class) if cls.startswith(uri)]\n",
    "non_range_domain_individuals_dict = {}\n",
    "for c in all_classes:\n",
    "    non_range_domain_individuals_dict[c] = get_non_domain_individuals(g, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f970c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_range_domain_violations(g_no_noise, range_domain_info, non_range_domain_individuals_dict, noise_percentage):    \n",
    "    max_triples = int(noise_percentage * len(g_no_noise))\n",
    "    \n",
    "    noisy_g_range_domain = rdflib.Graph()\n",
    "    noisy_g_range_domain += violate_domain(g_no_noise, range_domain_info, non_range_domain_individuals_dict, k = max_triples//2)\n",
    "    noisy_g_range_domain += violate_range(g_no_noise, range_domain_info, non_range_domain_individuals_dict, k = max_triples - (max_triples // 2))\n",
    "\n",
    "    new_g_range_domain = copy_graph(g_no_noise)\n",
    "    new_g_range_domain += violate_domain(g_no_noise, range_domain_info, non_range_domain_individuals_dict, k = max_triples//2)\n",
    "    new_g_range_domain += violate_range(g_no_noise, range_domain_info, non_range_domain_individuals_dict, k = max_triples - (max_triples // 2))\n",
    "\n",
    "    return noisy_g_range_domain, new_g_range_domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676690b-4924-4045-9932-7e0963792cdf",
   "metadata": {},
   "source": [
    "# 4. Get files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_percentage in [0.25, 0.5, 0.75, 1.0]:    \n",
    "    noisy_g_random, new_g_random = add_triples_random(g_no_noise, noise_percentage)\n",
    "    noisy_g_random.serialize(destination=f\"datasets/noise/{dataset_name}_random_{noise_percentage}.owl\", format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a140629",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f'models/RGCN_{dataset_name}')\n",
    "\n",
    "for noise_percentage in [0.25, 0.5, 0.75, 1.0]:\n",
    "    noisy_g_gnn, new_g_gnn = add_triples_gnn(g_no_noise, data, noise_percentage)\n",
    "    noisy_g_gnn.serialize(destination=f\"datasets/noise/{dataset_name}_gnn_{noise_percentage}.owl\", format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3773db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_percentage in [0.25 / 2, 0.5 / 2, 0.75 / 2, 1.0 / 2]:     \n",
    "    g_logical_contradictions = rdflib.Graph() \n",
    "\n",
    "    noisy_g_disjoint, new_g_disjoint = add_disjoint_axioms(g, g_no_noise, all_disjoint_classes, all_disjoint_properties, uri, noise_percentage)\n",
    "    noisy_g_disjoint.serialize(destination=f\"datasets/noise/{dataset_name}_disjoint_{noise_percentage}.owl\", format='xml')\n",
    "\n",
    "    noisy_g_range_domain, new_g_range_domain = add_range_domain_violations(g_no_noise, range_domain_info, non_range_domain_individuals_dict, noise_percentage)\n",
    "    noisy_g_range_domain.serialize(destination=f\"datasets/noise/{dataset_name}_range_domain_{noise_percentage}.owl\", format='xml')\n",
    "\n",
    "    g_logical_contradictions += noisy_g_disjoint\n",
    "    g_logical_contradictions += noisy_g_range_domain\n",
    "    g_logical_contradictions.serialize(destination=f\"datasets/noise/{dataset_name}_logical_{noise_percentage*2}.owl\", format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = get_experimets(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7887b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in experiments[1:]: \n",
    "    \n",
    "    dataset_name = experiment['dataset_name']\n",
    "    file_name = experiment['file_name']\n",
    "    print(file_name)\n",
    "\n",
    "    g_train = rdflib.Graph()\n",
    "    g_train.parse(f'datasets/{dataset_name}_train.owl', format='turtle')\n",
    "    print(f'# G_train: {len(g_train)}')\n",
    "\n",
    "    g_noise = rdflib.Graph()\n",
    "    g_noise.parse(f'datasets/noise/{file_name}.owl')\n",
    "    print(f'# G_noise: {len(g_noise)}')\n",
    "\n",
    "    g_train += g_noise\n",
    "    g_train.serialize(destination=f'datasets/{file_name}_train.owl')\n",
    "    print(f'# G_train + G_noise: {len(g_train)}')\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
