{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "761fa5f2-c0ad-4fea-84bc-6ecbcf759d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n",
      "\n",
      "Warning: SQLite3 version 3.40.0 and 3.41.2 have huge performance regressions; please install version 3.41.1 or 3.42!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "import rdflib\n",
    "from rdflib import Namespace, Literal\n",
    "from owlready2 import get_ontology\n",
    "\n",
    "from src.utils import *\n",
    "from src.gnn import *\n",
    "from src.sparql_queries import *\n",
    "from src.noise import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f479add1-d4dd-44ff-9119-cd18dd1edd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f51ef75-efba-4f30-8032-42ed4b0fc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = 'family'\n",
    "# dataset_name = 'pizza'\n",
    "dataset_name = 'OWL2DL-1'\n",
    "# dataset_name = 'lubm_filtered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da7b16e0-0fa3-4d0a-988d-4d2f1bc3cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == 'family':\n",
    "    uri = Namespace(\"http://www.co-ode.org/roberts/family-tree.owl#\")\n",
    "elif dataset_name == 'pizza':\n",
    "    uri = Namespace(\"http://www.co-ode.org/ontologies/pizza/pizza.owl#\")\n",
    "elif dataset_name.startswith('OWL2DL-'):\n",
    "    uri = Namespace(\"https://kracr.iiitd.edu.in/OWL2Bench#\")\n",
    "elif dataset_name.startswith('lubm'):\n",
    "    uri = Namespace(\"http://swat.cse.lehigh.edu/onto/univ-bench.owl#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df7d31-b741-44b4-a997-e17df3218285",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "182adee3-c4ac-4a76-9897-5b17c7f42b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplets found in OWL2DL-1.owl: 55101\n",
      "Triplets found in OWL2DL-1.owl: 87662\n"
     ]
    }
   ],
   "source": [
    "g = rdflib.Graph()\n",
    "g.parse(f'datasets/{dataset_name}.owl')\n",
    "num_triples = len(g)\n",
    "print(f'Triplets found in {dataset_name}.owl: %d' % num_triples)\n",
    "\n",
    "g_no_noise = rdflib.Graph()\n",
    "g_no_noise.parse(f'datasets/{dataset_name}_train.owl', format='turtle')\n",
    "num_triples_train = len(g_no_noise)\n",
    "print(f'Triplets found in {dataset_name}.owl: %d' % num_triples_train)\n",
    "\n",
    "ontology = get_ontology(f'datasets/{dataset_name}.owl').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd34f1e-e8ed-41cb-ade2-598e51112aba",
   "metadata": {},
   "source": [
    "# 2. GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f51d2d9a-ca9a-49bc-a6ce-de64cb017415",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, nodes, nodes_dict, relations, relations_dict = get_data(g_no_noise)\n",
    "nodes_dict_rev = {value: key for key, value in nodes_dict.items()}\n",
    "relations_dict_rev = {value: key for key, value in relations_dict.items()}\n",
    "data = split_edges(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c9a71d9-df0a-4987-a2ad-eded19f4b5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  edge_index=[2, 87662],\n",
       "  edge_type=[87662],\n",
       "  val_pos_edge_index=[2, 0],\n",
       "  val_edge_type=[0],\n",
       "  test_pos_edge_index=[2, 17532],\n",
       "  test_edge_type=[17532],\n",
       "  train_pos_edge_index=[2, 70130],\n",
       "  train_edge_type=[70130]\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c27ccc-782b-4e6f-813f-10a72e01f989",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ad75650-5fe6-4014-be3b-8c90272091bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6932\n",
      "Epoch: 1, Loss: 0.6778\n",
      "Epoch: 2, Loss: 0.5739\n",
      "Epoch: 3, Loss: 0.5082\n",
      "Epoch: 4, Loss: 0.4547\n",
      "Epoch: 5, Loss: 0.3819\n",
      "Epoch: 6, Loss: 0.5966\n",
      "Epoch: 7, Loss: 0.3212\n",
      "Epoch: 8, Loss: 0.3092\n",
      "Epoch: 9, Loss: 0.2815\n",
      "Epoch: 10, Loss: 0.2302\n",
      "Run time: 55 seconds, 1 minutes\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "model = GNN(device, len(nodes), len(relations))\n",
    "\n",
    "for epoch in range(10+1):\n",
    "    loss = model._train(data.to(device))\n",
    "    print(f'Epoch: {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "torch.save(model, f'models/RGCN_{dataset_name}')\n",
    "et = time.time()\n",
    "elapsed_time = et - st\n",
    "print(f'Run time: {elapsed_time:.0f} seconds, {elapsed_time/60:.0f} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3695fb2-fc34-4c40-acec-10cf70f9a7e9",
   "metadata": {},
   "source": [
    "**Eval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "477909fa-bce0-499c-bd3a-98f42897aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(f'models/RGCN_{dataset_name}')\n",
    "# mrr, mean_rank, median_rank, hits_at_5, hits_at_10 = model._eval(data.to(device))\n",
    "# print(f'MRR: {mrr:.3f}, Mean Rank: {mean_rank:.3f}, Median Rank: {median_rank:.3f}, Hits@5: {hits_at_5:.3f}, Hits@10: {hits_at_10:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e038ffe5-3423-49df-bd62-f69964b062d4",
   "metadata": {},
   "source": [
    "# 3. Noise Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae62b8-d00d-4593-b777-cbc253abf2e0",
   "metadata": {},
   "source": [
    "## 3.1. GNN: we add k triples with a low prediction score to the ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fccf98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dictionary of nodes that only contains individuals\n",
    "_, individual_names, _ = get_individuals(g_no_noise)\n",
    "\n",
    "nodes_dict_rev_new = {}\n",
    "lst = []\n",
    "i = 0\n",
    "for k,v in nodes_dict_rev.items():\n",
    "    if v in individual_names:\n",
    "        nodes_dict_rev_new[i] = v\n",
    "        lst.append(k)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c4dcc0c-2c24-499b-a3b3-77bc5814aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_triples_gnn(g_no_noise, data, noise_percentage):\n",
    "\n",
    "    possible_predicates = get_possible_predicates(g_no_noise)\n",
    "    max_triples = int((noise_percentage * len(g_no_noise)) / len(possible_predicates))\n",
    "    \n",
    "    noisy_g_gnn = rdflib.Graph()\n",
    "    new_g_gnn = copy_graph(g_no_noise)\n",
    "    \n",
    "    for key, value in tqdm(relations_dict_rev.items()): \n",
    "        if str(value) in possible_predicates: \n",
    "            mask = data.edge_type == key\n",
    "            edge_index = torch.tensor([data.edge_index[0, mask].tolist(), data.edge_index[1, mask].tolist()])\n",
    "            edge_type = data.edge_type[mask]\n",
    "\n",
    "            output = model.model.encode(edge_index.to(model.device), edge_type.to(model.device))\n",
    "\n",
    "            link_pred_scores = torch.matmul(output, output.T)\n",
    "            output_norm = torch.norm(output, dim=1, keepdim=True)\n",
    "            link_pred_scores_norm = link_pred_scores / (output_norm * output_norm.T)\n",
    "\n",
    "            # We do not want to generate links that already exists\n",
    "            link_pred_scores_norm[edge_index[0,:],edge_index[1,:]] = 1\n",
    "\n",
    "            # We want the subject and object to be an individual \n",
    "            subset = link_pred_scores_norm[lst][:, lst]\n",
    "\n",
    "            # Find the indices of the top k smallest elements\n",
    "            _, topk_indices = torch.topk(subset.flatten(), max_triples*2, largest=False)\n",
    "            row_indices = topk_indices // subset.size(1)\n",
    "            col_indices = topk_indices % subset.size(1)\n",
    "\n",
    "            # Filter out indices where row index is greater than column index\n",
    "            valid_indices_mask = row_indices < col_indices\n",
    "            row_indices = row_indices[valid_indices_mask]\n",
    "            col_indices = col_indices[valid_indices_mask]\n",
    "\n",
    "            # Add generated triples\n",
    "            node1_lst = [nodes_dict_rev_new[row] for row in row_indices.tolist()]\n",
    "            node2_lst = [nodes_dict_rev_new[col] for col in col_indices.tolist()]\n",
    "            edge_type_uri = relations_dict_rev[key]\n",
    "            noisy_g_gnn = add_links(noisy_g_gnn, node1_lst, node2_lst, edge_type_uri)\n",
    "            new_g_gnn = add_links(new_g_gnn, node1_lst, node2_lst, edge_type_uri)\n",
    "            \n",
    "    return noisy_g_gnn, new_g_gnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da772b78-efc7-4218-867e-fce6407fae7a",
   "metadata": {},
   "source": [
    "## 3.2. Random: we add k random triples to the ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48ff7cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_triples_random(g_no_noise, uri, noise_percentage):\n",
    "    max_triples = int(noise_percentage * len(g_no_noise)) \n",
    "\n",
    "    noisy_g_random = rdflib.Graph()\n",
    "    new_g_random = copy_graph(g_no_noise)\n",
    "    num_triples = 0\n",
    "\n",
    "    possible_predicates = get_possible_predicates(g_no_noise)\n",
    "    subjects, objects = get_subjects_objects_given_predicate(g_no_noise, [str(uri).split(\"#\")[-1] for uri in possible_predicates], uri)\n",
    "\n",
    "    while num_triples < max_triples:\n",
    "        s = random.choice(subjects)\n",
    "        p = random.choice(possible_predicates)\n",
    "        o = random.choice(objects)\n",
    "\n",
    "        triple = (s, URIRef(uri + p), o)\n",
    "\n",
    "        if triple not in g_no_noise:\n",
    "            noisy_g_random.add(triple)\n",
    "            new_g_random.add(triple)\n",
    "            num_triples += 1\n",
    "    return noisy_g_random, new_g_random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc41e03-83f1-47a9-bb9e-db0f20d6fe18",
   "metadata": {},
   "source": [
    "## 3.3. DL: we add individuals to the ontology that belong to disjoint classes/properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "982897fe-4e91-41f7-be06-d4066d0bdc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 361\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 362\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 364\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 365\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 448\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 452\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 457\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 462\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 489\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 535\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 536\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 537\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 546\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 551\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 441\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 471\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 477\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 490\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 492\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 493\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 494\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 495\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 496\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 497\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 440\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 453\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 456\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 458\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 461\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 472\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 473\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 474\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_disjoint_classes = get_disjoint_classes(ontology)\n",
    "all_disjoint_properties = get_disjoint_properties(ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2e422d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_disjoint_axioms(g, g_no_noise, all_disjoint_classes, all_disjoint_properties, uri, noise_percentage):    \n",
    "    max_triples = int((noise_percentage * len(g_no_noise))/2)\n",
    "\n",
    "    noisy_g_disjoint = rdflib.Graph()\n",
    "    noisy_g_disjoint += add_noise_disjoint_classes(g_no_noise, max_triples, all_disjoint_classes, uri)\n",
    "    noisy_g_disjoint += add_noise_disjoint_properties(g, g_no_noise, max_triples, all_disjoint_properties, uri)\n",
    "\n",
    "    new_g_disjoint = copy_graph(g_no_noise)\n",
    "    new_g_disjoint += add_noise_disjoint_classes(g_no_noise, max_triples, all_disjoint_classes, uri)\n",
    "    new_g_disjoint += add_noise_disjoint_properties(g, g_no_noise, max_triples, all_disjoint_properties, uri)\n",
    "    return noisy_g_disjoint, new_g_disjoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676690b-4924-4045-9932-7e0963792cdf",
   "metadata": {},
   "source": [
    "# 4. Get files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d37a653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_percentage in [0.25, 0.5, 0.75, 1.0]:    \n",
    "    noisy_g_random, new_g_random = add_triples_random(g_no_noise, uri, noise_percentage)\n",
    "    noisy_g_random.serialize(destination=f\"datasets/noise/{dataset_name}_random_{noise_percentage}.owl\", format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "931370dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We created new individuals...\n",
      "We created new individuals...\n",
      "We created new individuals...\n",
      "We created new individuals...\n",
      "We created new individuals...\n",
      "We created new individuals...\n",
      "We created new individuals...\n",
      "We created new individuals...\n"
     ]
    }
   ],
   "source": [
    "for noise_percentage in [0.25, 0.5, 0.75, 1.0]:      \n",
    "    noisy_g_disjoint, new_g_disjoint = add_disjoint_axioms(g, g_no_noise, all_disjoint_classes, all_disjoint_properties, uri, noise_percentage)\n",
    "    noisy_g_disjoint.serialize(destination=f\"datasets/noise/{dataset_name}_disjoint_{noise_percentage}.owl\", format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6011df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [03:11<00:00,  2.04s/it]\n",
      "100%|██████████| 94/94 [03:34<00:00,  2.28s/it]\n",
      "100%|██████████| 94/94 [03:33<00:00,  2.27s/it]\n",
      "100%|██████████| 94/94 [03:32<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(f'models/RGCN_{dataset_name}')\n",
    "\n",
    "for noise_percentage in [0.25, 0.5, 0.75, 1.0]:\n",
    "    noisy_g_gnn, new_g_gnn = add_triples_gnn(g_no_noise, data, noise_percentage)\n",
    "    noisy_g_gnn.serialize(destination=f\"datasets/noise/{dataset_name}_gnn_{noise_percentage}.owl\", format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "903d1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = get_experimets(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7887b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# G_train: 87662\n",
      "# G_noise: 21900\n",
      "# G_train + G_noise: 109562\n",
      "\n",
      "# G_train: 87662\n",
      "# G_noise: 21913\n",
      "# G_train + G_noise: 109575\n",
      "\n",
      "# G_train: 87662\n",
      "# G_noise: 21278\n",
      "# G_train + G_noise: 108526\n",
      "\n",
      "# G_train: 87662\n",
      "# G_noise: 43803\n",
      "# G_train + G_noise: 131465\n",
      "\n",
      "# G_train: 87662\n",
      "# G_noise: 43831\n",
      "# G_train + G_noise: 131493\n",
      "\n",
      "# G_train: 87662\n",
      "# G_noise: 41532\n",
      "# G_train + G_noise: 128441\n",
      "\n",
      "# G_train: 87662\n",
      "# G_noise: 65751\n",
      "# G_train + G_noise: 153413\n",
      "\n",
      "# G_train: 87662\n",
      "# G_noise: 65741\n",
      "# G_train + G_noise: 153403\n",
      "\n",
      "# G_train: 87662\n",
      "# G_noise: 60592\n",
      "# G_train + G_noise: 147230\n",
      "\n",
      "# G_train: 87662\n",
      "# G_noise: 87650\n",
      "# G_train + G_noise: 175312\n",
      "\n",
      "# G_train: 87662\n",
      "# G_noise: 87650\n",
      "# G_train + G_noise: 175312\n",
      "\n",
      "# G_train: 87662\n",
      "# G_noise: 79169\n",
      "# G_train + G_noise: 165633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for experiment in experiments[1:]: \n",
    "    dataset_name = experiment['dataset_name']\n",
    "    file_name = experiment['file_name']\n",
    "\n",
    "    g_train = rdflib.Graph()\n",
    "    g_train.parse(f'datasets/{dataset_name}_train.owl', format='turtle')\n",
    "    print(f'# G_train: {len(g_train)}')\n",
    "\n",
    "    g_noise = rdflib.Graph()\n",
    "    g_noise.parse(f'datasets/noise/{file_name}.owl')\n",
    "    print(f'# G_noise: {len(g_noise)}')\n",
    "\n",
    "    g_train += g_noise\n",
    "    g_train.serialize(destination=f'datasets/{file_name}_train.owl')\n",
    "    print(f'# G_train + G_noise: {len(g_train)}')\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
