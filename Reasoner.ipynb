{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47422e52-7ae7-4afc-a3f3-20cf7a20fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch\n",
    "import rdflib\n",
    "\n",
    "import mowl\n",
    "mowl.init_jvm('10g')\n",
    "from mowl.datasets import PathDataset\n",
    "from mowl.projection import OWL2VecStarProjector\n",
    "from mowl.projection.edge import Edge\n",
    "from mowl.walking import DeepWalk\n",
    "from mowl.kge import KGEModel\n",
    "\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from src.gnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c1ea03-e1f9-47a5-bad6-3a2d1ba55f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'family'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fdc678-638d-44a5-8287-8201b24e2429",
   "metadata": {},
   "source": [
    "**Split ontology into train/test ontologies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04371f18-dec9-4435-8df5-9f9c60a72270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_ontology(file_name, train_ratio):\n",
    "    g = rdflib.Graph()\n",
    "    g.parse(f'datasets/{file_name}.owl')  \n",
    "    print(f'Triplets found: %d' % len(g))\n",
    "\n",
    "    individuals = list(g.subjects(predicate=None, object=None)) \n",
    "    random.shuffle(individuals) \n",
    "\n",
    "    split_index = int(train_ratio * len(individuals))\n",
    "\n",
    "    train_individuals = individuals[:split_index]\n",
    "    test_individuals = individuals[split_index:]\n",
    "\n",
    "    train_graph = rdflib.Graph()\n",
    "    test_graph = rdflib.Graph()\n",
    "\n",
    "    for individual in train_individuals:\n",
    "        for s, p, o in g.triples((individual, None, None)):\n",
    "            train_graph.add((s, p, o))\n",
    "\n",
    "    for individual in test_individuals:\n",
    "        for s, p, o in g.triples((individual, None, None)):\n",
    "            test_graph.add((s, p, o))\n",
    "\n",
    "    train_graph.serialize(destination=f'datasets/{file_name}_train.owl')\n",
    "    print(f'Train Triplets found: %d' % len(train_graph))\n",
    "    test_graph.serialize(destination=f'datasets/{file_name}_test.owl')\n",
    "    print(f'Test Triplets found: %d' % len(test_graph))\n",
    "    \n",
    "    return train_graph, test_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07910b87-8566-49b2-8da4-6f422a829427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplets found: 5017\n",
      "Train Triplets found: 4939\n",
      "Test Triplets found: 2812\n"
     ]
    }
   ],
   "source": [
    "train_graph, test_graph = split_ontology(file_name=file_name, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22612b87-2ffd-447b-96da-be028821cbd5",
   "metadata": {},
   "source": [
    "**OWL2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42bf3b66-bb2c-41b9-9c02-838512217d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def owl2vec_fit(file_name, embed_dim, load):\n",
    "    dataset = PathDataset(ontology_path=f'datasets/{file_name}_train.owl',\n",
    "                          testing_path=f'datasets/{file_name}_test.owl')\n",
    "    if not load:\n",
    "        projector = OWL2VecStarProjector(bidirectional_taxonomy=True)\n",
    "        edges = projector.project(dataset.ontology)\n",
    "        walker = DeepWalk(num_walks=20,\n",
    "                          walk_length=20,\n",
    "                          alpha=0.1,\n",
    "                          workers=4)         \n",
    "        walks = walker.walk(edges)\n",
    "        sentences = LineSentence(walker.outfile)\n",
    "        model = Word2Vec(sentences, vector_size=embed_dim, epochs=10, window=5, min_count=1, workers=4)\n",
    "        model.save(f'models/owl2vec.model')\n",
    "    else:\n",
    "        model = Word2Vec.load(f'models/owl2vec.model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "311e3fb8-a842-429e-bb85-e262f8dbdebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading Word2Vec object from models/owl2vec.model\n",
      "INFO:gensim.utils:loading wv recursively from models/owl2vec.model.wv.* with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute cum_table to None\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'fname': 'models/owl2vec.model', 'datetime': '2024-03-12T11:39:15.978886', 'gensim': '4.3.1', 'python': '3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "owl2vec_model = owl2vec_fit(file_name='family', embed_dim=200, load=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eeeed3-6c8b-4f3b-bf8e-88a091f782df",
   "metadata": {},
   "source": [
    "**Eval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ffc2af6-f8b3-4ee3-b5a4-c4be1a2493cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = owl2vec_model.wv\n",
    "words = list(owl2vec_model.wv.key_to_index)\n",
    "output_owl2vec = torch.tensor(vectors[words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec89a123-c75b-4f07-bb61-0ec2a729ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(set(words))\n",
    "nodes_dict = {node: i for i, node in enumerate(nodes)}\n",
    "nodes_dict_rev = {value: key for key, value in nodes_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4db126c0-1e54-4a9a-8734-c73d022b5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "edge_data = defaultdict(list)\n",
    "for s, p, o in test_graph.triples((None, None, None)):\n",
    "    s = s.n3()\n",
    "    s = s.replace('<','')\n",
    "    s = s.replace('>','')\n",
    "    o = o.n3()\n",
    "    o = o.replace('<','')\n",
    "    o = o.replace('>','')\n",
    "    try:\n",
    "        src, dst = nodes_dict[s], nodes_dict[o]\n",
    "        edge_data['edge_index'].append([src, dst])\n",
    "    except:\n",
    "        i+=1\n",
    "edge_index = torch.tensor(edge_data['edge_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6153917-3acc-4760-b3e7-ddffd99be75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.000, Hits@10: 1.000\n"
     ]
    }
   ],
   "source": [
    "hits1, hits10 = eval_hits(edge_index=edge_index,\n",
    "                          tail_pred=1,\n",
    "                          output=output_owl2vec,\n",
    "                          max_num=edge_index.size(1))\n",
    "print(f'Hits@1: {hits1:.3f}, Hits@10: {hits10:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25dd64a-3e4d-42d9-b159-f37d46698c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
