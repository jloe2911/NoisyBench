{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e168883c-69ca-41f3-be58-20cb77fbd5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rdflib\n",
    "from rdflib import URIRef, RDF\n",
    "from owlready2 import get_ontology\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import logging\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e60086c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'OWL2DL-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600bfeb3",
   "metadata": {},
   "source": [
    "**Filter unnecessary triples from g and i**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69ae5631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Subject-Resources: 3668\n"
     ]
    }
   ],
   "source": [
    "ontology = get_ontology(f'datasets/{dataset_name}.owl').load()\n",
    "subject_resources = list(ontology.individuals())\n",
    "named_individuals = [URIRef(x.iri) for x in subject_resources]\n",
    "print(f'# Subject-Resources: {len(subject_resources)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2890122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_triples(inferred_path, filtered_inferred_path):    \n",
    "    g_inferred = rdflib.Graph()\n",
    "    g_inferred.parse(inferred_path, format=\"ttl\")\n",
    "    g_inferred_filtered = rdflib.Graph()\n",
    "    for triple in g_inferred: \n",
    "        if triple[0] in named_individuals or triple[2] in named_individuals:\n",
    "            g_inferred_filtered.add(triple)\n",
    "    g_inferred_filtered.serialize(filtered_inferred_path, format=\"ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_graph_path in tqdm(sorted(glob('MyJenaProject/input/' + \"*\"))):\n",
    "    filter_triples(input_graph_path, input_graph_path.replace('input','input_filtered'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eef997",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_graph_path in tqdm(sorted(glob('MyJenaProject/output/' + \"*\"))):\n",
    "    filter_triples(input_graph_path, input_graph_path.replace('output','output_filtered'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d70fcc",
   "metadata": {},
   "source": [
    "**Create train, test, val sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "95250b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_type(s):\n",
    "    s = s.split('/')[-1]\n",
    "    s = s.split('_')[:-1]\n",
    "    s = \"_\".join(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42ff4939-7885-4f6d-98b4-d011f54210d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_df(INPUT_GRAPHS_FOLDER, INFERENCE_GRAPHS_FOLDER):\n",
    "    logging.info(f\"Creating dataframe for {dataset_name} input/inference pairs\")\n",
    "    rdf_files = []\n",
    "    for input_graph_path in tqdm(sorted(glob(INPUT_GRAPHS_FOLDER + \"*\"))):\n",
    "        input_graph_file = os.path.basename(input_graph_path)\n",
    "        inference_path = INFERENCE_GRAPHS_FOLDER + input_graph_file.replace('.ttl','_inferred.ttl')\n",
    "        graph_type = get_graph_type(input_graph_path)\n",
    "        rdf_pair = {\"input_graph_file\": input_graph_path, \"inference_file\": inference_path, \"graph_type\": graph_type}\n",
    "        rdf_files.append(rdf_pair)\n",
    "    files_df = pd.DataFrame.from_dict(rdf_files)\n",
    "    return files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2609afd2-3d09-4ad1-b397-55b8bb44559a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3662/3662 [00:00<00:00, 197289.01it/s]\n"
     ]
    }
   ],
   "source": [
    "files_df = get_files_df('MyJenaProject/input_filtered/', 'MyJenaProject/output_filtered/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f717b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove classes for which only one instance exists\n",
    "df_count = pd.DataFrame(files_df['graph_type'].value_counts())\n",
    "graph_type_2_keep = df_count[df_count['count'] > 1].index\n",
    "files_df = files_df[files_df['graph_type'].isin(graph_type_2_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5830f0dc-339f-4454-a3f5-31ac8a29dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, train_percent=0.6, validate_percent=0.2, stratify=None, seed=1):\n",
    "    val_test_percent = 1 - train_percent\n",
    "    test_percent = (1 - (train_percent + validate_percent))\n",
    "    test_percent = test_percent / (test_percent + validate_percent)\n",
    "    if stratify:\n",
    "        df_train, df_val_test = train_test_split(df, test_size=val_test_percent, random_state=seed,\n",
    "                                                 stratify=df[stratify])\n",
    "        df_val, df_test = train_test_split(df_val_test, test_size=test_percent, random_state=seed,\n",
    "                                           stratify=df_val_test[stratify])\n",
    "    else:\n",
    "        df_train, df_val_test = train_test_split(df, test_size=val_test_percent, random_state=seed)\n",
    "        df_val, df_test = train_test_split(df_val_test, test_size=test_percent, random_state=seed)\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e959ea23-2a80-4381-958c-49fbe2a079c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_data_train, rdf_data_val, rdf_data_test = train_validate_test_split(files_df,\n",
    "                                                                        train_percent=0.6,\n",
    "                                                                        validate_percent=0.2,\n",
    "                                                                        stratify=\"graph_type\",\n",
    "                                                                        seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b9886c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_nt_files_with_rdflib(data, output_file, old_iri, new_iri):\n",
    "    merged_graph = rdflib.Graph()\n",
    "\n",
    "    nt_files_orig = data.get('input_graph_file', pd.Series(dtype=str))\n",
    "    nt_files_inferred = data.get('inference_file', pd.Series(dtype=str))\n",
    "    tbox_path = pd.Series([f'datasets/{dataset_name}_TBOX.owl'])\n",
    "    \n",
    "    nt_files = pd.concat([nt_files_orig, nt_files_inferred, tbox_path], ignore_index=True)\n",
    "\n",
    "    for nt_file in nt_files:\n",
    "        try:\n",
    "            graph = rdflib.Graph()\n",
    "            if 'TBOX' in nt_file: graph.parse(nt_file)\n",
    "            else: graph.parse(nt_file, format=\"turtle\")\n",
    "            if old_iri and new_iri:\n",
    "                for s, p, o in graph:\n",
    "                    s = URIRef(str(s).replace(old_iri, new_iri)) if isinstance(s, URIRef) else s\n",
    "                    p = URIRef(str(p).replace(old_iri, new_iri)) if isinstance(p, URIRef) else p\n",
    "                    o = URIRef(str(o).replace(old_iri, new_iri)) if isinstance(o, URIRef) else o\n",
    "                    merged_graph.add((s, p, o))\n",
    "            else:\n",
    "                merged_graph += graph  \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not parse {nt_file} - {e}\")\n",
    "\n",
    "    merged_graph.serialize(destination=output_file)\n",
    "    print(f\"Merged file created at {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10c58b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file created at datasets/bin/OWL2DL-1_train.owl\n",
      "Merged file created at datasets/bin/OWL2DL-1_val.owl\n",
      "Merged file created at datasets/bin/OWL2DL-1_test.owl\n"
     ]
    }
   ],
   "source": [
    "merge_nt_files_with_rdflib(rdf_data_train, f'datasets/bin/{dataset_name}_train.owl', \n",
    "              'https://kracr.iiitd.edu.in/OWL2Bench', 'https://kracr.iiitd.edu.in/OWL2Bench_train')\n",
    "merge_nt_files_with_rdflib(rdf_data_val, f'datasets/bin/{dataset_name}_val.owl', \n",
    "              'https://kracr.iiitd.edu.in/OWL2Bench', 'https://kracr.iiitd.edu.in/OWL2Bench_val')\n",
    "merge_nt_files_with_rdflib(rdf_data_test, f'datasets/bin/{dataset_name}_test.owl', \n",
    "              'https://kracr.iiitd.edu.in/OWL2Bench', 'https://kracr.iiitd.edu.in/OWL2Bench_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cfd2ce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We do not want that validation and test sets contain individuals or classes that were unseen in the training set\n",
    "# train_graph = rdflib.Graph()\n",
    "# train_graph.parse(f'datasets/bin/{dataset_name}_train.owl', format='turtle')\n",
    "\n",
    "# valid_graph = rdflib.Graph()\n",
    "# valid_graph.parse(f'datasets/bin/{dataset_name}_val.owl', format='turtle')\n",
    "\n",
    "# test_graph = rdflib.Graph()\n",
    "# test_graph.parse(f'datasets/bin/{dataset_name}_test.owl', format='turtle')\n",
    "\n",
    "# train_individuals = set(train_graph.subjects())\n",
    "# train_classes = set(train_graph.objects(predicate=URIRef(\"http://www.w3.org/2002/07/owl#type\")))\n",
    "\n",
    "# def filter_graph(original_graph, train_individuals, train_classes):\n",
    "#     filtered_graph = rdflib.Graph()\n",
    "#     for s, p, o in original_graph:\n",
    "#         if s in train_classes or o in train_classes:\n",
    "#             filtered_graph.add((s, p, o))\n",
    "#         if s in train_individuals or o in train_individuals:\n",
    "#             filtered_graph.add((s, p, o))\n",
    "#         if p == URIRef('http://www.w3.org/2000/01/rdf-schema#subClassOf'):\n",
    "#             filtered_graph.add((s, p, o))\n",
    "#     return filtered_graph\n",
    "\n",
    "# valid_filtered_graph = filter_graph(valid_graph, train_individuals, train_classes)\n",
    "# valid_filtered_graph.serialize(f'datasets/bin/{dataset_name}_val.owl', format='turtle')\n",
    "# print(f'Valid graph before filtering: {len(valid_graph)}')\n",
    "# print(f'Valid graph before filtering: {len(valid_filtered_graph)}')\n",
    "\n",
    "# test_filtered_graph = filter_graph(test_graph, train_individuals, train_classes)\n",
    "# test_filtered_graph.serialize(f'datasets/bin/{dataset_name}_test.owl', format='turtle')\n",
    "# print(f'Test graph before filtering: {len(test_graph)}')\n",
    "# print(f'Test graph before filtering: {len(test_filtered_graph)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651feb78",
   "metadata": {},
   "source": [
    "**Add noise to training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "44c92bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = get_experimets(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ba8ce8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# G_train: 50230\n",
      "# G_noise: 13801\n",
      "# G_train + G_noise: 64031\n",
      "\n",
      "# G_train: 50230\n",
      "# G_noise: 27604\n",
      "# G_train + G_noise: 77834\n",
      "\n",
      "# G_train: 50230\n",
      "# G_noise: 41405\n",
      "# G_train + G_noise: 91635\n",
      "\n",
      "# G_train: 50230\n",
      "# G_noise: 55242\n",
      "# G_train + G_noise: 105472\n",
      "\n",
      "# G_train: 50230\n",
      "# G_noise: 13683\n",
      "# G_train + G_noise: 63913\n",
      "\n",
      "# G_train: 50230\n",
      "# G_noise: 27362\n",
      "# G_train + G_noise: 77592\n",
      "\n",
      "# G_train: 50230\n",
      "# G_noise: 41013\n",
      "# G_train + G_noise: 91243\n",
      "\n",
      "# G_train: 50230\n",
      "# G_noise: 54711\n",
      "# G_train + G_noise: 104941\n",
      "\n",
      "# G_train: 50230\n",
      "# G_noise: 13873\n",
      "# G_train + G_noise: 62853\n",
      "\n",
      "# G_train: 50230\n",
      "# G_noise: 27673\n",
      "# G_train + G_noise: 76653\n",
      "\n",
      "# G_train: 50230\n",
      "# G_noise: 41477\n",
      "# G_train + G_noise: 90457\n",
      "\n",
      "# G_train: 50230\n",
      "# G_noise: 55277\n",
      "# G_train + G_noise: 104257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for experiment in experiments[1:]: \n",
    "    dataset_name = experiment['dataset_name']\n",
    "    file_name = experiment['file_name']\n",
    "    format_ = experiment['format_']\n",
    "    add_noise = experiment['add_noise']  \n",
    "\n",
    "    g_train = rdflib.Graph()\n",
    "    g_train.parse(f'datasets/bin/{dataset_name}_train.owl', format='turtle')\n",
    "    print(f'# G_train: {len(g_train)}')\n",
    "\n",
    "    g_noise = rdflib.Graph()\n",
    "    g_noise.parse(f'datasets/noise/{file_name}.owl')\n",
    "    print(f'# G_noise: {len(g_noise)}')\n",
    "\n",
    "    g_train += g_noise\n",
    "    g_train.serialize(destination=f'datasets/bin/{file_name}_train.owl')\n",
    "    print(f'# G_train + G_noise: {len(g_train)}')\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
