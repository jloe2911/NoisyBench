{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e168883c-69ca-41f3-be58-20cb77fbd5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rdflib\n",
    "from owlready2 import get_ontology\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95250b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_type(s):\n",
    "    s = s.split('/')[-1]\n",
    "    s = s.split('_')[:-1]\n",
    "    s = \"_\".join(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42ff4939-7885-4f6d-98b4-d011f54210d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_df(INPUT_GRAPHS_FOLDER, INFERENCE_GRAPHS_FOLDER):\n",
    "    logging.info(\"Creating dataframe for OWL2DL-1 input/inference pairs\")\n",
    "    rdf_files = []\n",
    "    for input_graph_path in tqdm(sorted(glob(INPUT_GRAPHS_FOLDER + \"*\"))):\n",
    "        input_graph_file = os.path.basename(input_graph_path)\n",
    "        inference_path = INFERENCE_GRAPHS_FOLDER + input_graph_file.replace('.owl','_inferred.owl')\n",
    "        graph_type = get_graph_type(input_graph_path)\n",
    "        rdf_pair = {\"input_graph_file\": input_graph_path, \"inference_file\": inference_path, \"graph_type\": graph_type}\n",
    "        rdf_files.append(rdf_pair)\n",
    "    files_df = pd.DataFrame.from_dict(rdf_files)\n",
    "    return files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2609afd2-3d09-4ad1-b397-55b8bb44559a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3662/3662 [00:00<00:00, 129995.95it/s]\n"
     ]
    }
   ],
   "source": [
    "files_df = get_files_df('MyJenaProject/input/', 'MyJenaProject/output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f717b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove classes for which only one instance exists\n",
    "df_count = pd.DataFrame(files_df['graph_type'].value_counts())\n",
    "graph_type_2_keep = df_count[df_count['graph_type'] > 1].index\n",
    "files_df = files_df[files_df['graph_type'].isin(graph_type_2_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5830f0dc-339f-4454-a3f5-31ac8a29dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, train_percent=0.6, validate_percent=0.2, stratify=None, seed=1):\n",
    "    val_test_percent = 1 - train_percent\n",
    "    test_percent = (1 - (train_percent + validate_percent))\n",
    "    test_percent = test_percent / (test_percent + validate_percent)\n",
    "    if stratify:\n",
    "        df_train, df_val_test = train_test_split(df, test_size=val_test_percent, random_state=seed,\n",
    "                                                 stratify=df[stratify])\n",
    "        df_val, df_test = train_test_split(df_val_test, test_size=test_percent, random_state=seed,\n",
    "                                           stratify=df_val_test[stratify])\n",
    "    else:\n",
    "        df_train, df_val_test = train_test_split(df, test_size=val_test_percent, random_state=seed)\n",
    "        df_val, df_test = train_test_split(df_val_test, test_size=test_percent, random_state=seed)\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e959ea23-2a80-4381-958c-49fbe2a079c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_data_train, rdf_data_val, rdf_data_test = train_validate_test_split(files_df,\n",
    "                                                                        train_percent=0.6,\n",
    "                                                                        validate_percent=0.2,\n",
    "                                                                        stratify=\"graph_type\",\n",
    "                                                                        seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5682104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_owl_files(data, output_file):\n",
    "    # Define input files\n",
    "    nt_files_orig = data['input_graph_file']\n",
    "    nt_files_inferred = data['inference_file']\n",
    "    nt_files = pd.concat([nt_files_orig, nt_files_inferred])\n",
    "\n",
    "\n",
    "    # Start with an empty root element for OWL/RDF\n",
    "    rdf_root = None\n",
    "    namespaces = {}\n",
    "    \n",
    "    for file in nt_files:\n",
    "        tree = ET.parse(file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Gather namespaces\n",
    "        for k, v in root.attrib.items():\n",
    "            if k.startswith(\"xmlns\"):\n",
    "                namespaces[k] = v\n",
    "        \n",
    "        if rdf_root is None:\n",
    "            # First file, initialize the root\n",
    "            rdf_root = ET.Element(root.tag, attrib=namespaces)\n",
    "        \n",
    "        # Append the children from the current file to the root\n",
    "        for child in root:\n",
    "            rdf_root.append(child)\n",
    "    \n",
    "    # Write the merged content to the output file\n",
    "    tree = ET.ElementTree(rdf_root)\n",
    "    tree.write(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00051aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_owl_files(rdf_data_train, 'datasets/bin/OWL2DL-1_train.owl')\n",
    "merge_owl_files(rdf_data_val, 'datasets/bin/OWL2DL-1_val.owl')\n",
    "merge_owl_files(rdf_data_test, 'datasets/bin/OWL2DL-1_test.owl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a32897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_iri(file_path, new_iri):\n",
    "    onto = get_ontology(file_path).load()\n",
    "    onto.base_iri = new_iri\n",
    "    onto.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c3ebf7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Change the IRIs of the train, validation, and test datasets\n",
    "change_iri('datasets/bin/OWL2DL-1_train.owl', 'http://new-iri/train')\n",
    "change_iri('datasets/bin/OWL2DL-1_val.owl', 'http://new-iri/val')\n",
    "change_iri('datasets/bin/OWL2DL-1_test.owl', 'http://new-iri/test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
