{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e168883c-69ca-41f3-be58-20cb77fbd5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "from rdflib import URIRef, OWL, Literal, RDF, RDFS, BNode\n",
    "from owlready2 import get_ontology\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils import *\n",
    "from src.noise import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60086c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'OWL2DL-1'\n",
    "# dataset_name = 'family'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb2b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology = get_ontology(f'datasets/{dataset_name}.owl').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600bfeb3",
   "metadata": {},
   "source": [
    "**Filter unnecessary triples from inferred graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ae5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_properties = list(ontology.object_properties())\n",
    "object_properties = [URIRef(x.iri) for x in object_properties]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b69d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_inferred_triples(input_path, inferred_path, filtered_inferred_path):  \n",
    "    g = rdflib.Graph()\n",
    "    g.parse(input_path)  \n",
    "    g_inferred = rdflib.Graph()\n",
    "    g_inferred.parse(inferred_path)\n",
    "\n",
    "    g_inferred_filtered = rdflib.Graph()\n",
    "    for triple in g_inferred: \n",
    "        if ((triple[1] in object_properties or triple[1] in {RDFS.subClassOf, RDF.type}) and \n",
    "            not isinstance(triple[2], Literal) and \n",
    "            triple[0] != OWL.Thing and                            \n",
    "            triple[2] != OWL.Thing and    \n",
    "            triple[0] != OWL.Nothing and                            \n",
    "            triple[2] != OWL.Nothing and                                  \n",
    "            not isinstance(triple[0], BNode) and  \n",
    "            not isinstance(triple[2], BNode) and \n",
    "            triple[2] != RDFS.Resource and \n",
    "            triple not in g):\n",
    "            g_inferred_filtered.add(triple)\n",
    "    g_inferred_filtered.serialize(filtered_inferred_path, format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eef997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/67 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for input_graph_path in tqdm(sorted(glob(f'datasets/{dataset_name}_inferred_graphs/' + \"*\"))):\n",
    "\n",
    "    if 'xml' in input_graph_path:\n",
    "        file = input_graph_path.replace(f'datasets/{dataset_name}_inferred_graphs\\\\', '').replace('.xml', '')\n",
    "        input_path = f'datasets/{dataset_name}_input_graphs/' + file + '.ttl'\n",
    "        filtered_inferred_path = f'datasets/{dataset_name}_inferred_graphs_filtered/' + file + '.ttl'\n",
    "    else: \n",
    "        file = input_graph_path.replace(f'datasets/{dataset_name}_inferred_graphs\\\\', '')\n",
    "        input_path = f'datasets/{dataset_name}_input_graphs/' + file \n",
    "        inferred_path = input_graph_path\n",
    "        filtered_inferred_path = f'datasets/{dataset_name}_inferred_graphs_filtered/' + file \n",
    "\n",
    "    filter_inferred_triples(input_path, \n",
    "                            input_graph_path, \n",
    "                            filtered_inferred_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d70fcc",
   "metadata": {},
   "source": [
    "**Create test, val sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea4a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_type(s):\n",
    "    s = s.split('\\\\')[-1]\n",
    "    s = s.split('_')[:-1]\n",
    "    s = \"_\".join(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf21091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_df(INPUT_GRAPHS_FOLDER, INFERENCE_GRAPHS_FOLDER):\n",
    "    logging.info(f\"Creating dataframe for {dataset_name} input/inference pairs\")\n",
    "    rdf_files = []\n",
    "    for input_graph_path in tqdm(sorted(glob(INPUT_GRAPHS_FOLDER + \"*\"))):\n",
    "        input_graph_file = os.path.basename(input_graph_path)\n",
    "        inference_path = INFERENCE_GRAPHS_FOLDER + input_graph_file\n",
    "        graph_type = get_graph_type(input_graph_path)\n",
    "        rdf_pair = {\"input_graph_file\": input_graph_path, \"inference_file\": inference_path, \"graph_type\": graph_type}\n",
    "        rdf_files.append(rdf_pair)\n",
    "    files_df = pd.DataFrame.from_dict(rdf_files)\n",
    "    return files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df = get_files_df(f'datasets/{dataset_name}_input_graphs_filtered_1hop/', f'datasets/{dataset_name}_inferred_graphs_filtered/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf0920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove classes for which only one instance exists\n",
    "df_count = pd.DataFrame(files_df['graph_type'].value_counts())\n",
    "graph_type_2_keep = df_count[df_count['graph_type'] > 1].index\n",
    "files_df = files_df[files_df['graph_type'].isin(graph_type_2_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_val_split(df, test_percent, stratify, seed):\n",
    "    df_test, df_val = train_test_split(df, test_size=test_percent, random_state=seed, stratify=df[stratify])\n",
    "    return df_test, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7790f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_data_test, rdf_data_val = test_val_split(files_df, \n",
    "                                             test_percent=0.5,\n",
    "                                             stratify=\"graph_type\",\n",
    "                                             seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b5caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_nt_files(nt_files, output_file):\n",
    "    merged_graph = rdflib.Graph()\n",
    "\n",
    "    for nt_file in nt_files:\n",
    "        try:\n",
    "            graph = rdflib.Graph()\n",
    "            if 'TBOX' in nt_file: graph.parse(nt_file)\n",
    "            else: graph.parse(nt_file, format=\"turtle\")\n",
    "            merged_graph += graph  \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not parse {nt_file} - {e}\")\n",
    "\n",
    "    merged_graph.serialize(destination=output_file)\n",
    "    print(f\"Merged file created at {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2760b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_nt_files(rdf_data_test['inference_file'], f'datasets/{dataset_name}_test_complete.owl')\n",
    "merge_nt_files(rdf_data_val['inference_file'], f'datasets/{dataset_name}_val_complete.owl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8b8b88",
   "metadata": {},
   "source": [
    "**Manage duplicates and drop BNodes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182353e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train = rdflib.Graph()\n",
    "G_train.parse(f'datasets/{dataset_name}.owl')\n",
    "print(f'# triples in G_train: {len(G_train)}')\n",
    "\n",
    "G_test = rdflib.Graph()\n",
    "G_test.parse(f'datasets/{dataset_name}_test_complete.owl', format='turtle')\n",
    "print(f'# triples in G_test: {len(G_test)}')\n",
    "\n",
    "G_val = rdflib.Graph()\n",
    "G_val.parse(f'datasets/{dataset_name}_val_complete.owl', format='turtle')\n",
    "print(f'# triples in G_val: {len(G_val)}')\n",
    "\n",
    "G_tbox = rdflib.Graph()\n",
    "G_tbox.parse(f'datasets/{dataset_name}_TBOX.owl')\n",
    "print(f'# triples in G_tbox: {len(G_tbox)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c0dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_test += G_tbox\n",
    "G_val += G_tbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bnodes(graph):\n",
    "    new_graph = rdflib.Graph()\n",
    "    for s, p, o in graph:\n",
    "        if isinstance(s, BNode) or isinstance(p, BNode) or isinstance(o, BNode):\n",
    "            continue  \n",
    "        new_graph.add((s, p, o))\n",
    "    return new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cfde16",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_G_train = remove_bnodes(G_train)\n",
    "filtered_G_test = remove_bnodes(G_test)\n",
    "filtered_G_val = remove_bnodes(G_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c7aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(graph):\n",
    "    classes = set()\n",
    "    individuals = set()\n",
    "    relations = set()\n",
    "\n",
    "    for s, p, o in graph:\n",
    "        if (s, RDF.type, OWL.Class) in graph:\n",
    "            classes.add(s)\n",
    "        elif (o, RDF.type, OWL.Class) in graph:\n",
    "            classes.add(o)\n",
    "        \n",
    "        if (s, RDF.type, OWL.NamedIndividual) in graph:\n",
    "            individuals.add(s)\n",
    "        elif (o, RDF.type, OWL.NamedIndividual) in graph:\n",
    "            individuals.add(o)\n",
    "        \n",
    "        if isinstance(p, URIRef):\n",
    "            relations.add(p)\n",
    "\n",
    "    return classes, relations, individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca61b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_entities(train_graph, graph_to_modify):\n",
    "    train_classes, train_relations, train_individuals = get_entities(train_graph)\n",
    "    \n",
    "    classes, relations, individuals = get_entities(graph_to_modify)\n",
    "    \n",
    "    missing_classes = classes - train_classes\n",
    "    missing_relations = relations - train_relations\n",
    "    missing_individuals = individuals - train_individuals\n",
    "\n",
    "    for s, p, o in list(graph_to_modify):\n",
    "        if (s in missing_classes or o in missing_classes) or \\\n",
    "           (p in missing_relations) or \\\n",
    "           (s in missing_individuals or o in missing_individuals):\n",
    "            graph_to_modify.remove((s, p, o))\n",
    "\n",
    "    return graph_to_modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19eea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove classes, individuals or relations that have been inferred but are not present in the training set \n",
    "filtered_G_test = remove_missing_entities(filtered_G_train, filtered_G_test)\n",
    "filtered_G_val = remove_missing_entities(filtered_G_train, filtered_G_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f63be",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_G_train.serialize(f'datasets/{dataset_name}_train.owl')\n",
    "filtered_G_test.serialize(f'datasets/{dataset_name}_test.owl')\n",
    "filtered_G_val.serialize(f'datasets/{dataset_name}_val.owl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2e1c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'# triples in G_train: {len(filtered_G_train)}')\n",
    "print(f'# triples in G_test: {len(filtered_G_test)}')\n",
    "print(f'# triples in G_val: {len(filtered_G_val)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
