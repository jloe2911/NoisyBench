{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761fa5f2-c0ad-4fea-84bc-6ecbcf759d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "import rdflib\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from src.utils import *\n",
    "from src.gnn import *\n",
    "from src.sparql_queries import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df7d31-b741-44b4-a997-e17df3218285",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182adee3-c4ac-4a76-9897-5b17c7f42b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = rdflib.Graph()\n",
    "g.parse('datasets/family.owl')\n",
    "\n",
    "print(f'Triplets found: %d' % len(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b0c3a-2379-4ce2-8c29-f75430d64d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = list(set(g.predicates()))\n",
    "nodes = list(set(g.subjects()).union(set(g.objects())))\n",
    "\n",
    "relations_dict = {rel: i for i, rel in enumerate(relations)}\n",
    "nodes_dict = {node: i for i, node in enumerate(nodes)}\n",
    "\n",
    "nodes_dict_rev = {value: key for key, value in nodes_dict.items()}\n",
    "relations_dict_rev = {value: key for key, value in relations_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d2d9a-ca9a-49bc-a6ce-de64cb017415",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(g, nodes_dict, relations_dict)\n",
    "data = split_edges(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a71d9-df0a-4987-a2ad-eded19f4b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd34f1e-e8ed-41cb-ade2-598e51112aba",
   "metadata": {},
   "source": [
    "# 2. GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c27ccc-782b-4e6f-813f-10a72e01f989",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad75650-5fe6-4014-be3b-8c90272091bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "model = GNN()\n",
    "\n",
    "for epoch in range(300+1):\n",
    "    loss = model._train(data, len(nodes), len(relations))\n",
    "    if (epoch % 100) == 0:\n",
    "        hits1, hits10 = model._eval(data)\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}, Hits@1: {hits1:.3f}, Hits@10: {hits10:.3f}')\n",
    "\n",
    "torch.save(model, f'models/RGCN')\n",
    "et = time.time()\n",
    "elapsed_time = et - st\n",
    "print(f'Run time: {elapsed_time:.0f} seconds, {elapsed_time/60:.0f} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3695fb2-fc34-4c40-acec-10cf70f9a7e9",
   "metadata": {},
   "source": [
    "**Eval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477909fa-bce0-499c-bd3a-98f42897aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f'models/RGCN')\n",
    "hits1, hits10 = model._eval(data)\n",
    "print(f'Hits@1: {hits1:.3f}, Hits@10: {hits10:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e038ffe5-3423-49df-bd62-f69964b062d4",
   "metadata": {},
   "source": [
    "# 3. Generate New Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f88c59-d3d6-469d-8718-e5fad1e7952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [URIRef('http://www.co-ode.org/roberts/family-tree.owl#isBrotherOf'),\n",
    "        URIRef('http://www.co-ode.org/roberts/family-tree.owl#isFatherOf'),\n",
    "        URIRef('http://www.co-ode.org/roberts/family-tree.owl#isSonOf'),\n",
    "        URIRef('http://www.co-ode.org/roberts/family-tree.owl#isMalePartnerIn'),\n",
    "        URIRef('http://www.co-ode.org/roberts/family-tree.owl#isSisterOf'),\n",
    "        URIRef('http://www.co-ode.org/roberts/family-tree.owl#isMotherOf'),\n",
    "        URIRef('http://www.co-ode.org/roberts/family-tree.owl#isDaughterOf'),\n",
    "        URIRef('http://www.co-ode.org/roberts/family-tree.owl#isFemalePartnerIn')]\n",
    "edge_types = [relations_dict[key] for key in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec6a5ab-bbd7-413f-b8fb-f5e26c22921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = []\n",
    "qres = g.query(\"\"\"\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX fo: <http://www.co-ode.org/roberts/family-tree.owl#>\n",
    "SELECT ?s WHERE {\n",
    " ?s rdf:type owl:NamedIndividual .\n",
    "}\n",
    "\"\"\")\n",
    "for row in qres:\n",
    "    persons.append(row.s)\n",
    "person_id = [nodes_dict[person] for person in persons]\n",
    "person_names = [nodes_dict_rev[person_id] for person_id in person_id]\n",
    "person_names_dict = dict(zip(list(set(np.arange(len(person_id)))), person_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae62b8-d00d-4593-b777-cbc253abf2e0",
   "metadata": {},
   "source": [
    "### GNN: we add new links with a low prediction score to the ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4dcc0c-2c24-499b-a3b3-77bc5814aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_triples_gnn(g, data, edge_types, k):\n",
    "    noisy_g_gnn = rdflib.Graph()\n",
    "    new_g_gnn = copy_graph(g)\n",
    "    #for etype in tqdm(range(len(relations))):   \n",
    "    for etype in tqdm(edge_types):   \n",
    "        mask = data.edge_type == etype\n",
    "        edge_index = torch.tensor([data.edge_index[0,mask].tolist(),data.edge_index[1,mask].tolist()])\n",
    "        edge_type = data.edge_type[mask]\n",
    "\n",
    "        output = model.model.encode(edge_index, edge_type)\n",
    "\n",
    "        link_pred_scores = torch.matmul(output, output.T)\n",
    "        output_norm = torch.norm(output, dim=1, keepdim=True)\n",
    "        link_pred_scores_norm = link_pred_scores / (output_norm * output_norm.T)\n",
    "        \n",
    "        # We do not want to generate links that already exists\n",
    "        # We want the subject and object to be of type Person\n",
    "        link_pred_scores_norm[edge_index[0,:],edge_index[1,:]] = 1\n",
    "        subset = link_pred_scores_norm[person_id][:, person_id]\n",
    "\n",
    "        # Find the indices of the top k smallest elements\n",
    "        _, topk_indices = torch.topk(subset.flatten(), k*2, largest=False)\n",
    "        row_indices = topk_indices // subset.size(1)\n",
    "        col_indices = topk_indices % subset.size(1)\n",
    "\n",
    "        # Filter out indices where row index is greater than column index\n",
    "        valid_indices_mask = row_indices < col_indices\n",
    "        row_indices = row_indices[valid_indices_mask]\n",
    "        col_indices = col_indices[valid_indices_mask]\n",
    "        \n",
    "        # Add generated triples\n",
    "        node1_lst = [person_names_dict[key] for key in row_indices.tolist()]\n",
    "        node2_lst = [person_names_dict[key] for key in col_indices.tolist()]\n",
    "        edge_type_uri = relations_dict_rev[etype]\n",
    "        noisy_g_gnn = add_links(noisy_g_gnn, node1_lst, node2_lst, edge_type_uri)\n",
    "        new_g_gnn = add_links(new_g_gnn, node1_lst, node2_lst, edge_type_uri)\n",
    "        \n",
    "    return noisy_g_gnn, new_g_gnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da772b78-efc7-4218-867e-fce6407fae7a",
   "metadata": {},
   "source": [
    "### Random: we add random links to the ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7762fba-c109-4ab8-b6f5-64a94a2e8c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_triples_random(g, data, edge_types, k):\n",
    "    noisy_g_random = rdflib.Graph()\n",
    "    new_g_random = copy_graph(g)\n",
    "    #for etype in tqdm(range(len(relations))):  \n",
    "    for etype in tqdm(edge_types):   \n",
    "        mask = data.edge_type == etype\n",
    "        edge_index = torch.tensor([data.edge_index[0,mask].tolist(),data.edge_index[1,mask].tolist()])\n",
    "        \n",
    "        # We do not want to generate links that already exists\n",
    "        # We want the subject and object to be of type Person\n",
    "        num_neg_samples = 0\n",
    "        candidate_heads = []\n",
    "        candidate_tails = []\n",
    "        new_person_id = person_id * (int(k/len(person_id)) + 1)\n",
    "        heads = new_person_id.copy()\n",
    "        tails = new_person_id.copy()\n",
    "        random.shuffle(heads)\n",
    "        random.shuffle(tails)\n",
    "        \n",
    "        while num_neg_samples < k:    \n",
    "            h = heads[num_neg_samples]\n",
    "            t = tails[num_neg_samples]\n",
    "            if h not in edge_index[0] or t not in edge_index[1]:\n",
    "                candidate_heads.append(h)\n",
    "                candidate_tails.append(t)\n",
    "            num_neg_samples += 1\n",
    "        \n",
    "        # Add generated triples\n",
    "        node1_lst = [nodes_dict_rev[key] for key in candidate_heads]\n",
    "        node2_lst = [nodes_dict_rev[key] for key in candidate_tails]\n",
    "        edge_type_uri = relations_dict_rev[etype]\n",
    "        noisy_g_random = add_links(noisy_g_random, node1_lst, node2_lst, edge_type_uri)\n",
    "        new_g_random = add_links(new_g_random, node1_lst, node2_lst, edge_type_uri)\n",
    "\n",
    "    return noisy_g_random, new_g_random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676690b-4924-4045-9932-7e0963792cdf",
   "metadata": {},
   "source": [
    "# 4. Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72a515-07c1-4780-8c25-0e4372e68e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add k triples per edge_type\n",
    "k = 100\n",
    "model = torch.load(f'models/RGCN')\n",
    "\n",
    "noisy_g_gnn, new_g_gnn = add_triples_gnn(g, data, edge_types, k)\n",
    "noisy_g_gnn.serialize(destination=f\"datasets/family_noisy_gnn_{k}.owl\")\n",
    "noisy_g_random, new_g_random = add_triples_random(g, data, edge_types, k)\n",
    "noisy_g_random.serialize(destination=f\"datasets/family_noisy_random_{k}.owl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db4ba1-6081-44b2-ba99-bfbdaa58fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1, query2, query3, query4, query5, query6, query7 = get_queries()\n",
    "\n",
    "print(f'Triplets found: %d' % len(new_g_gnn))\n",
    "print('Contradictions:')\n",
    "for q in [query1, query2, query3, query4, query5, query6, query7]:\n",
    "    print_result(new_g_gnn, q)\n",
    "\n",
    "print(f'Triplets found: %d' % len(new_g_random))\n",
    "print('Contradictions:')\n",
    "for q in [query1, query2, query3, query4, query5, query6, query7]:\n",
    "    print_result(new_g_random, q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
