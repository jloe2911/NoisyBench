{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47422e52-7ae7-4afc-a3f3-20cf7a20fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "import mowl\n",
    "mowl.init_jvm('10g')\n",
    "from mowl.datasets import PathDataset\n",
    "from mowl.projection import OWL2VecStarProjector\n",
    "from mowl.walking import DeepWalk\n",
    "\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "from src.gnn import *\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa895ae4-b0ec-4c68-985d-cd1823f306db",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [{'file_name' : 'family',\n",
    "                'format_' : None,\n",
    "                'add_noise': False},\n",
    "               {'file_name' : 'family_noisy_gnn_100',\n",
    "                'format_' : 'ttl',\n",
    "                'add_noise': True},\n",
    "               {'file_name' : 'family_noisy_gnn_1000',\n",
    "                'format_' : 'ttl',\n",
    "                'add_noise': True},\n",
    "               #{'file_name' : 'family_noisy_gnn_10000',\n",
    "               # 'format_' : 'ttl',\n",
    "               # 'add_noise': True},\n",
    "               #{'file_name' : 'family_noisy_gnn_100000',\n",
    "               # 'format_' : 'ttl',\n",
    "               # 'add_noise': True},\n",
    "               {'file_name' : 'family_noisy_random_100',\n",
    "                'format_' : 'ttl',\n",
    "                'add_noise': True},\n",
    "               {'file_name' : 'family_noisy_random_1000',\n",
    "                'format_' : 'ttl',\n",
    "                'add_noise': True}#,\n",
    "               #{'file_name' : 'family_noisy_random_10000',\n",
    "               # 'format_' : 'ttl'},\n",
    "               #{'file_name' : 'family_noisy_random_100000',\n",
    "               #'format_' : 'ttl'}\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c12e9-b5da-44ae-9ca5-4b5162b62af7",
   "metadata": {},
   "source": [
    "**Fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42bf3b66-bb2c-41b9-9c02-838512217d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def owl2vec_fit(file_name, embed_dim, load):\n",
    "    dataset = PathDataset(ontology_path=f'datasets/bin/{file_name}_train.owl',\n",
    "                          testing_path=f'datasets/bin/{file_name}_test.owl')\n",
    "    if not load:\n",
    "        projector = OWL2VecStarProjector(bidirectional_taxonomy=True)\n",
    "        edges = projector.project(dataset.ontology)\n",
    "        walker = DeepWalk(num_walks=20,\n",
    "                          walk_length=20,\n",
    "                          alpha=0.1,\n",
    "                          workers=4)         \n",
    "        walks = walker.walk(edges)\n",
    "        sentences = LineSentence(walker.outfile)\n",
    "        model = Word2Vec(sentences, vector_size=embed_dim, epochs=500, window=5, min_count=1, workers=4)\n",
    "        model.save(f'models/owl2vec_{file_name}.model')\n",
    "    else:\n",
    "        model = Word2Vec.load(f'models/owl2vec_{file_name}.model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eeeed3-6c8b-4f3b-bf8e-88a091f782df",
   "metadata": {},
   "source": [
    "**Eval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86f87119-1628-4331-8191-d842c7772a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def owl2vec_eval(owl2vec_model, test_graph):\n",
    "    vectors = owl2vec_model.wv\n",
    "    words = list(owl2vec_model.wv.key_to_index)\n",
    "    output_owl2vec = torch.tensor(vectors[words])\n",
    "    \n",
    "    nodes = list(set(words))\n",
    "    nodes_dict = {node: i for i, node in enumerate(nodes)}\n",
    "    \n",
    "    i=0\n",
    "    edge_data = defaultdict(list)\n",
    "    for s, p, o in test_graph.triples((None, None, None)):\n",
    "        s = s.n3()\n",
    "        s = s.replace('<','')\n",
    "        s = s.replace('>','')\n",
    "        o = o.n3()\n",
    "        o = o.replace('<','')\n",
    "        o = o.replace('>','')\n",
    "        try:\n",
    "            src, dst = nodes_dict[s], nodes_dict[o]\n",
    "            edge_data['edge_index'].append([src, dst])\n",
    "        except:\n",
    "            i+=1\n",
    "    edge_index = torch.tensor(edge_data['edge_index']).reshape(2,-1)\n",
    "    \n",
    "    hits1, hits10 = eval_hits(edge_index=edge_index,\n",
    "                              tail_pred=1,\n",
    "                              output=output_owl2vec,\n",
    "                              max_num=100)\n",
    "    print(f'Hits@1: {hits1:.3f}, Hits@10: {hits10:.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625a210-4e24-44da-bdd2-b892e3cd4325",
   "metadata": {},
   "source": [
    "**Experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04bfe98-f759-46fa-883a-3df2b6af61eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplets found in family.owl: 5017\n",
      "Train Triplets found: 4013\n",
      "Test Triplets found: 1004\n",
      "Valid Triplets found: 0\n",
      "Hits@1: 0.034, Hits@10: 0.184\n",
      "\n",
      "Triplets found in family.owl: 5017\n",
      "Triplets found in family_noisy_gnn_100.owl: 800\n",
      "Train Triplets found: 4813\n",
      "Test Triplets found: 1004\n",
      "Valid Triplets found: 0\n",
      "Hits@1: 0.004, Hits@10: 0.108\n",
      "\n",
      "Triplets found in family.owl: 5017\n",
      "Triplets found in family_noisy_gnn_1000.owl: 7997\n",
      "Train Triplets found: 12010\n",
      "Test Triplets found: 1004\n",
      "Valid Triplets found: 0\n",
      "Hits@1: 0.030, Hits@10: 0.155\n",
      "\n",
      "Triplets found in family.owl: 5017\n",
      "Triplets found in family_noisy_random_100.owl: 778\n",
      "Train Triplets found: 4791\n",
      "Test Triplets found: 1004\n",
      "Valid Triplets found: 0\n",
      "Hits@1: 0.045, Hits@10: 0.208\n",
      "\n",
      "Triplets found in family.owl: 5017\n",
      "Triplets found in family_noisy_random_1000.owl: 7841\n",
      "Train Triplets found: 11854\n",
      "Test Triplets found: 1004\n",
      "Valid Triplets found: 0\n",
      "Hits@1: 0.029, Hits@10: 0.181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for experiment in experiments: \n",
    "    file_name = experiment['file_name']\n",
    "    format_ = experiment['format_']\n",
    "    add_noise = experiment['add_noise']\n",
    "\n",
    "    train_graph, test_graph, valid_graph = split_ontology(file_name=file_name, format_=format_, train_ratio=0.8, test_ratio=0.2, add_noise=add_noise)\n",
    "    owl2vec_model = owl2vec_fit(file_name=file_name, embed_dim=200, load=False)\n",
    "    owl2vec_eval(owl2vec_model, test_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
